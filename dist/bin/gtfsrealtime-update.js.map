{"version":3,"sources":["../../src/bin/gtfsrealtime-update.ts","../../src/lib/file-utils.ts","../../src/lib/log-utils.ts","../../src/lib/import-gtfs.ts","../../src/models/gtfs-realtime/trip-updates.ts","../../src/models/gtfs-realtime/stop-time-updates.ts","../../src/models/gtfs-realtime/vehicle-positions.ts","../../src/models/gtfs-realtime/service-alerts.ts","../../src/models/gtfs-realtime/service-alert-informed_entities.ts","../../src/lib/db.ts","../../src/lib/geojson-utils.ts","../../src/lib/import-gtfs-realtime.ts","../../src/lib/utils.ts","../../src/lib/export.ts","../../src/lib/advancedQuery.ts","../../src/lib/gtfs/routes.ts","../../src/lib/gtfs/shapes.ts","../../src/lib/gtfs/stops.ts","../../src/lib/gtfs/stop-times.ts","../../src/lib/gtfs/trips.ts"],"sourcesContent":["#!/usr/bin/env node\n\nimport yargs from 'yargs';\nimport { hideBin } from 'yargs/helpers';\nimport PrettyError from 'pretty-error';\n\nimport { getConfig } from '../lib/file-utils.ts';\nimport { formatError } from '../lib/log-utils.ts';\nimport { updateGtfsRealtime } from '../index.ts';\nimport type { Config } from '../types/global_interfaces.ts';\nconst pe = new PrettyError();\n\nconst argv = yargs(hideBin(process.argv))\n  .usage('Usage: $0 --configPath ./config.json')\n  .help()\n  .option('c', {\n    alias: 'configPath',\n    describe: 'Path to config file',\n    type: 'string',\n  })\n  .default('configPath', undefined)\n  .parseSync();\n\nconst handleError = (error = 'Unknown Error') => {\n  process.stdout.write(`\\n${formatError(error)}\\n`);\n  console.error(pe.render(error));\n  process.exit(1);\n};\n\nconst setupImport = async () => {\n  const config = await getConfig({\n    configPath: argv.configPath,\n  });\n  await updateGtfsRealtime(config as Config);\n  process.exit();\n};\n\nsetupImport().catch(handleError);\n","import path from 'node:path';\nimport { existsSync } from 'node:fs';\nimport { homedir } from 'node:os';\nimport { mkdir, readFile, rm } from 'node:fs/promises';\nimport { omit, snakeCase } from 'lodash-es';\nimport sanitize from 'sanitize-filename';\nimport StreamZip from 'node-stream-zip';\nimport type { Config } from '../types/global_interfaces.ts';\n\nimport { log } from './log-utils.ts';\n\nconst homeDirectory = homedir();\n\n/** Configuration command line arguments interface */\ninterface ConfigArgs {\n  configPath?: string;\n  gtfsPath?: string;\n  gtfsUrl?: string;\n  sqlitePath?: string;\n}\n\n/**\n * Attempts to parse and load configuration from various sources\n * Priority: 1. CLI config path 2. CLI direct args 3. ./config.json\n * @param {ConfigArgs} argv - Command line arguments\n * @throws {Error} If configuration cannot be found or parsed\n * @returns {Promise<Record<string, any>>} Parsed configuration object\n * @example\n * const config = await getConfig({ configPath: './my-config.json' });\n */\nexport async function getConfig(argv: ConfigArgs): Promise<Config> {\n  let config;\n  let data;\n\n  try {\n    if (argv.configPath) {\n      const configPath = path.resolve(untildify(argv.configPath));\n      data = await readFile(configPath, 'utf8');\n      config = Object.assign(JSON.parse(data), argv);\n    } else if (argv.gtfsPath || argv.gtfsUrl || argv.sqlitePath) {\n      const agencies = [\n        ...(argv.gtfsPath ? [{ path: argv.gtfsPath }] : []),\n        ...(argv.gtfsUrl ? [{ url: argv.gtfsUrl }] : []),\n      ];\n\n      config = {\n        agencies,\n        ...omit(argv, ['path', 'url']),\n      };\n    } else if (existsSync(path.resolve('./config.json'))) {\n      data = await readFile(path.resolve('./config.json'), 'utf8');\n      config = Object.assign(JSON.parse(data), argv);\n      log(config)('Using configuration from ./config.json');\n    } else {\n      throw new Error(\n        'Cannot find configuration file. Use config-sample.json as a starting point, pass --configPath option.',\n      );\n    }\n\n    return config;\n  } catch (error) {\n    if (error instanceof SyntaxError) {\n      throw new Error(\n        `Cannot parse configuration file. Check to ensure that it is valid JSON. Error: ${error.message}`,\n      );\n    }\n    throw error;\n  }\n}\n\n/**\n * Prepares a directory for saving files by clearing its contents\n * @param {string} exportPath - Path to the directory to prepare\n * @returns {Promise<void>}\n * @example\n * await prepDirectory('./output');\n */\nexport async function prepDirectory(exportPath: string): Promise<void> {\n  await rm(exportPath, { recursive: true, force: true });\n  await mkdir(exportPath, { recursive: true });\n}\n\n/**\n * Extracts contents of a zip file to specified directory\n * @param {string} zipfilePath - Path to the zip file\n * @param {string} exportPath - Directory to extract contents to\n * @returns {Promise<void>}\n * @throws {Error} If zip file cannot be opened or extracted\n * @example\n * await unzip('./data.zip', './extracted');\n */\nexport async function unzip(\n  zipfilePath: string,\n  exportPath: string,\n): Promise<void> {\n  try {\n    const zip = new StreamZip.async({ file: zipfilePath });\n    await zip.extract(null, exportPath);\n    await zip.close();\n  } catch (error) {\n    throw new Error(\n      `Failed to extract zip file: ${error instanceof Error ? error.message : 'Unknown error'}`,\n    );\n  }\n}\n\n/**\n * Generates a safe folder name from input string\n * Converts to snake_case and removes unsafe characters\n * @param {string} folderName - Input string to convert to folder name\n * @returns {string} Sanitized folder name\n * @example\n * generateFolderName('My Folder!') // returns 'my_folder'\n */\nexport function generateFolderName(folderName: string): string {\n  if (!folderName || typeof folderName !== 'string') {\n    throw new Error('Folder name must be a non-empty string');\n  }\n  return snakeCase(sanitize(folderName));\n}\n\n/**\n * Converts a tilde path to a full path\n * @param pathWithTilde The path to convert\n * @returns The full path\n */\nexport function untildify(pathWithTilde: string): string {\n  return homeDirectory\n    ? pathWithTilde.replace(/^~(?=$|\\/|\\\\)/, homeDirectory)\n    : pathWithTilde;\n}\n","import { clearLine, cursorTo } from 'node:readline';\nimport { noop } from 'lodash-es';\nimport * as colors from 'yoctocolors';\nimport { Config } from '../types/global_interfaces.ts';\n\n/** Function type for logging with optional line overwrite */\ntype LogFunction = (text: string, overwrite?: boolean) => void;\n\n/**\n * Creates a logging function based on configuration settings\n * @param {Config} config - Configuration object containing logging preferences\n * @returns {LogFunction} Logging function that writes to stdout, or noop if verbose is false\n * @example\n * const logger = log({ verbose: true });\n * logger('Processing...', true); // Overwrites current line\n * logger('Done!'); // Writes on new line\n */\nexport function log(config: Config): LogFunction {\n  if (config.verbose === false) {\n    return noop;\n  }\n\n  if (config.logFunction) {\n    return config.logFunction;\n  }\n\n  return (text: string, overwrite = false): void => {\n    if (overwrite && process.stdout.isTTY) {\n      clearLine(process.stdout, 0);\n      cursorTo(process.stdout, 0);\n    } else {\n      process.stdout.write('\\n');\n    }\n\n    process.stdout.write(text);\n  };\n}\n\n/**\n * Creates a warning logging function\n * @param {Config} config - Configuration object containing logging preferences\n * @returns {(text: string) => void} Function that logs formatted warning messages\n * @example\n * const warnLogger = logWarning(config);\n * warnLogger('Resource not found'); // Outputs yellow warning message\n */\nexport function logWarning(config: Config): (text: string) => void {\n  if (config.logFunction) {\n    return config.logFunction;\n  }\n\n  return (text: string): void => {\n    process.stdout.write(`\\n${formatWarning(text)}\\n`);\n  };\n}\n\n/**\n * Creates an error logging function\n * @param {Config} config - Configuration object containing logging preferences\n * @returns {(text: string) => void} Function that logs formatted error messages\n * @example\n * const errorLogger = logError(config);\n * errorLogger('Failed to connect'); // Outputs red error message\n */\nexport function logError(config: Config): (text: string) => void {\n  if (config.logFunction) {\n    return config.logFunction;\n  }\n\n  return (text: string): void => {\n    process.stdout.write(`\\n${formatError(text)}\\n`);\n  };\n}\n\n/**\n * Formats warning text with yellow color and underline\n * @param {string} text - The warning message to format\n * @returns {string} Formatted warning message in yellow with underlined \"Warning\" prefix\n * @example\n * const formattedWarning = formatWarning('Resource not found');\n * console.log(formattedWarning); // Yellow \"Warning: Resource not found\"\n */\nexport function formatWarning(text: string): string {\n  return colors.yellow(`${colors.underline('Warning')}: ${text}`);\n}\n\n/**\n * Formats error text with red color and underline\n * @param {Error | string} error - The error object or message to format\n * @returns {string} Formatted error message in red with underlined \"Error\" prefix\n * @example\n * const formattedError = formatError(new Error('Connection failed'));\n * console.log(formattedError); // Red \"Error: Connection failed\"\n */\nexport function formatError(error: Error | string): string {\n  const messageText = error instanceof Error ? error.message : error;\n  const cleanMessage = messageText.replace(/^Error:\\s*/i, '');\n\n  return colors.red(`${colors.underline('Error')}: ${cleanMessage}`);\n}\n","import path from 'node:path';\nimport { createReadStream, existsSync, lstatSync } from 'node:fs';\nimport { cp, readdir, rename, readFile, rm, writeFile } from 'node:fs/promises';\nimport { parse } from 'csv-parse';\nimport stripBomStream from 'strip-bom-stream';\nimport { temporaryDirectory } from 'tempy';\nimport mapSeries from 'promise-map-series';\nimport Database from 'better-sqlite3';\n\nimport * as models from '../models/models.ts';\nimport { openDb } from './db.ts';\nimport { untildify, unzip } from './file-utils.ts';\nimport { isValidJSON } from './geojson-utils.ts';\nimport { updateGtfsRealtimeData } from './import-gtfs-realtime.ts';\nimport { log, logError, logWarning } from './log-utils.ts';\nimport {\n  getTimestampColumnName,\n  padLeadingZeros,\n  applyPrefixToValue,\n  pluralize,\n  setDefaultConfig,\n  validateConfigForImport,\n} from './utils.ts';\n\nimport {\n  Config,\n  ConfigAgency,\n  Model,\n  SqlValue,\n  TableNames,\n} from '../types/global_interfaces.ts';\n\ninterface GtfsImportTask {\n  exclude?: TableNames[];\n  url?: string;\n  headers?: Record<string, string>;\n  realtimeAlerts?: {\n    url: string;\n    headers?: Record<string, string>;\n  };\n  realtimeTripUpdates?: {\n    url: string;\n    headers?: Record<string, string>;\n  };\n  realtimeVehiclePositions?: {\n    url: string;\n    headers?: Record<string, string>;\n  };\n  downloadDir: string;\n  downloadTimeout?: number;\n  gtfsRealtimeExpirationSeconds: number;\n  path?: string;\n  csvOptions: object;\n  ignoreDuplicates: boolean;\n  ignoreErrors: boolean;\n  sqlitePath: string;\n  prefix?: string;\n  currentTimestamp: number;\n  log: (message: string, newLine?: boolean) => void;\n  logWarning: (message: string) => void;\n  logError: (message: string) => void;\n}\n\nconst getTextFiles = async (folderPath: string): Promise<string[]> => {\n  const files = await readdir(folderPath);\n  return files.filter((filename) => filename.slice(-3) === 'txt');\n};\n\nconst downloadGtfsFiles = async (task: GtfsImportTask): Promise<void> => {\n  if (!task.url) {\n    throw new Error('No `url` specified in config');\n  }\n\n  task.log(`Downloading GTFS from ${task.url}`);\n\n  task.path = `${task.downloadDir}/gtfs.zip`;\n\n  const response = await fetch(task.url, {\n    method: 'GET',\n    headers: task.headers || {},\n    signal: task.downloadTimeout\n      ? AbortSignal.timeout(task.downloadTimeout)\n      : undefined,\n  });\n\n  if (response.status !== 200) {\n    throw new Error(\n      `Unable to download GTFS from ${task.url}. Got status ${response.status}.`,\n    );\n  }\n\n  const buffer = await response.arrayBuffer();\n\n  await writeFile(task.path, Buffer.from(buffer));\n  task.log('Download successful');\n};\n\nconst extractGtfsFiles = async (task: GtfsImportTask): Promise<void> => {\n  if (!task.path) {\n    throw new Error('No `path` specified in config');\n  }\n\n  const gtfsPath = untildify(task.path);\n  task.log(`Importing static GTFS from ${task.path}\\r`);\n  if (path.extname(gtfsPath) === '.zip') {\n    try {\n      await unzip(gtfsPath, task.downloadDir);\n      const textFiles = await getTextFiles(task.downloadDir);\n\n      // If no .txt files in this directory, check for subdirectories and copy them here\n      if (textFiles.length === 0) {\n        const files = await readdir(task.downloadDir);\n        // Ignore system directories within zip file\n        const folders = files\n          .filter((filename) => !['__MACOSX'].includes(filename))\n          .map((filename) => path.join(task.downloadDir, filename))\n          .filter((source) => lstatSync(source).isDirectory());\n\n        if (folders.length > 1) {\n          throw new Error(\n            `More than one subfolder found in zip file at \\`${task.path}\\`. Ensure that .txt files are in the top level of the zip file, or in a single subdirectory.`,\n          );\n        } else if (folders.length === 0) {\n          throw new Error(\n            `No .txt files found in \\`${task.path}\\`. Ensure that .txt files are in the top level of the zip file, or in a single subdirectory.`,\n          );\n        }\n\n        const subfolderName = folders[0];\n        const directoryTextFiles = await getTextFiles(subfolderName);\n\n        if (directoryTextFiles.length === 0) {\n          throw new Error(\n            `No .txt files found in \\`${task.path}\\`. Ensure that .txt files are in the top level of the zip file, or in a single subdirectory.`,\n          );\n        }\n\n        await Promise.all(\n          directoryTextFiles.map(async (fileName) =>\n            rename(\n              path.join(subfolderName, fileName),\n              path.join(task.downloadDir, fileName),\n            ),\n          ),\n        );\n      }\n    } catch (error: unknown) {\n      task.logError(error as string);\n      throw new Error(`Unable to unzip file ${task.path}`);\n    }\n  } else {\n    // Local file is unzipped, just copy it from there.\n    try {\n      await cp(gtfsPath, task.downloadDir, { recursive: true });\n    } catch {\n      throw new Error(\n        `Unable to load files from path \\`${gtfsPath}\\` defined in configuration. Verify that path exists and contains GTFS files.`,\n      );\n    }\n  }\n};\n\nconst createGtfsTables = (db: Database.Database): void => {\n  for (const model of Object.values(models) as Model[]) {\n    if (!model.schema) {\n      return;\n    }\n\n    const sqlColumnCreateStatements = [];\n\n    for (const column of model.schema) {\n      const checks = [];\n      if (column.min !== undefined && column.max) {\n        checks.push(\n          `${column.name} >= ${column.min} AND ${column.name} <= ${column.max}`,\n        );\n      } else if (column.min) {\n        checks.push(`${column.name} >= ${column.min}`);\n      } else if (column.max) {\n        checks.push(`${column.name} <= ${column.max}`);\n      }\n\n      if (column.type === 'integer') {\n        checks.push(\n          `(TYPEOF(${column.name}) = 'integer' OR ${column.name} IS NULL)`,\n        );\n      } else if (column.type === 'real') {\n        checks.push(\n          `(TYPEOF(${column.name}) = 'real' OR ${column.name} IS NULL)`,\n        );\n      }\n\n      const required = column.required ? 'NOT NULL' : '';\n      const columnDefault = column.default ? 'DEFAULT ' + column.default : '';\n      const columnCollation = column.nocase ? 'COLLATE NOCASE' : '';\n      const checkClause =\n        checks.length > 0 ? `CHECK(${checks.join(' AND ')})` : '';\n\n      sqlColumnCreateStatements.push(\n        `${column.name} ${column.type} ${checkClause} ${required} ${columnDefault} ${columnCollation}`,\n      );\n\n      // Add an additional timestamp column for time columns\n      if (column.type === 'time') {\n        sqlColumnCreateStatements.push(\n          `${getTimestampColumnName(column.name)} INTEGER GENERATED ALWAYS AS (\n            CASE\n              WHEN ${column.name} IS NULL OR ${column.name} = '' THEN NULL\n              ELSE CAST(\n                substr(${column.name}, 1, instr(${column.name}, ':') - 1) * 3600 +\n                substr(${column.name}, instr(${column.name}, ':') + 1, 2) * 60 +\n                substr(${column.name}, -2) AS INTEGER\n              )\n            END\n          ) STORED`,\n        );\n      }\n    }\n\n    // Find Primary Key fields\n    const primaryColumns = model.schema.filter((column) => column.primary);\n\n    if (primaryColumns.length > 0) {\n      sqlColumnCreateStatements.push(\n        `PRIMARY KEY (${primaryColumns.map(({ name }) => name).join(', ')})`,\n      );\n    }\n\n    db.prepare(`DROP TABLE IF EXISTS ${model.filenameBase};`).run();\n\n    db.prepare(\n      `CREATE TABLE ${model.filenameBase} (${sqlColumnCreateStatements.join(', ')});`,\n    ).run();\n  }\n};\n\nconst createGtfsIndexes = (db: Database.Database): void => {\n  for (const model of Object.values(models) as Model[]) {\n    if (!model.schema) {\n      return;\n    }\n    for (const column of model.schema) {\n      if (column.index) {\n        db.prepare(\n          `CREATE INDEX idx_${model.filenameBase}_${column.name} ON ${model.filenameBase} (${column.name});`,\n        ).run();\n      }\n\n      if (column.type === 'time') {\n        // Index all timestamp columns\n        const timestampColumnName = getTimestampColumnName(column.name);\n        db.prepare(\n          `CREATE INDEX idx_${model.filenameBase}_${timestampColumnName} ON ${model.filenameBase} (${timestampColumnName});`,\n        ).run();\n      }\n    }\n  }\n};\n\nconst formatGtfsLine = (\n  line: { [x: string]: string | null },\n  model: Model,\n  totalLineCount: number,\n): Record<string, string | null> => {\n  const lineNumber = totalLineCount + 1;\n  const formattedLine: Record<string, string | null> = {};\n  const filenameBase = model.filenameBase;\n  const filenameExtension = model.filenameExtension;\n\n  for (const { name, type, required } of model.schema) {\n    let value: string | null = line[name];\n\n    // Early null check\n    if (value === '' || value === undefined || value === null) {\n      formattedLine[name] = null;\n\n      if (required) {\n        throw new Error(\n          `Missing required value in ${filenameBase}.${filenameExtension} for ${name} on line ${lineNumber}.`,\n        );\n      }\n      continue;\n    }\n\n    if (type === 'date') {\n      // Handle YYYY-MM-DD format\n      value = value?.toString().replace(/-/g, '');\n      if (value.length !== 8) {\n        throw new Error(\n          `Invalid date in ${filenameBase}.${filenameExtension} for ${name} on line ${lineNumber}.`,\n        );\n      }\n    } else if (type === 'time') {\n      value = padLeadingZeros(value);\n    }\n\n    if (type === 'json') {\n      value = JSON.stringify(value);\n    }\n\n    formattedLine[name] = value;\n  }\n\n  return formattedLine;\n};\n\nconst BATCH_SIZE = 100_000;\n\nconst importGtfsFiles = async (\n  db: Database.Database,\n  task: GtfsImportTask,\n): Promise<void> => {\n  await mapSeries(\n    Object.values(models),\n    (model: Model) =>\n      new Promise<void>((resolve, reject) => {\n        let totalLineCount = 0;\n        const filename = `${model.filenameBase}.${model.filenameExtension}`;\n\n        // Skip any models that are excluded by config\n        if (task.exclude && task.exclude.includes(model.filenameBase)) {\n          task.log(`Skipping - ${filename}\\r`);\n          resolve();\n          return;\n        }\n\n        // Skip gtfs-realtime models not present in static GTFS\n        if (model.extension === 'gtfs-realtime') {\n          resolve();\n          return;\n        }\n\n        const filepath = path.join(task.downloadDir, `${filename}`);\n\n        // Log missing standard GTFS files, don't log nonstandard files\n        if (!existsSync(filepath)) {\n          if (!model.nonstandard) {\n            task.log(`Importing - ${filename} - No file found\\r`);\n          }\n\n          resolve();\n          return;\n        }\n\n        task.log(`Importing - ${filename}\\r`);\n\n        // Create a list of all columns\n        const columns = model.schema;\n\n        // Create a map of which columns need prefixing\n        const prefixedColumns = new Set(\n          columns\n            .filter((column) => column.prefix)\n            .map((column) => column.name),\n        );\n\n        const prepareStatement = `INSERT ${task.ignoreDuplicates ? 'OR IGNORE' : ''} INTO ${\n          model.filenameBase\n        } (${columns.map(({ name }) => name).join(', ')}) VALUES (${columns\n          .map(({ name }) => `@${name}`)\n          .join(', ')})`;\n\n        const insert = db.prepare(prepareStatement);\n\n        const insertLines = db.transaction((lines) => {\n          for (const [rowNumber, line] of Object.entries(lines)) {\n            try {\n              if (task.prefix === undefined) {\n                insert.run(line);\n              } else {\n                const prefixedLine = Object.fromEntries(\n                  Object.entries(\n                    line as { [x: string]: unknown; geojson?: string },\n                  ).map(([columnName, value]) => [\n                    columnName,\n                    applyPrefixToValue(\n                      value as string,\n                      prefixedColumns.has(columnName),\n                      task.prefix,\n                    ),\n                  ]),\n                );\n                insert.run(prefixedLine);\n              }\n            } catch (error: unknown) {\n              if (\n                (error as Error & { code?: string }).code ===\n                'SQLITE_CONSTRAINT_PRIMARYKEY'\n              ) {\n                const primaryColumns = columns.filter(\n                  (column) => column.primary,\n                );\n                task.logWarning(\n                  `Duplicate values for primary key (${primaryColumns.map((column) => column.name).join(', ')}) found in ${filename}. Set the \\`ignoreDuplicates\\` option to true in config.json to ignore this error`,\n                );\n              }\n\n              task.logWarning(\n                `Check ${filename} for invalid data on line ${rowNumber + 1}.`,\n              );\n              throw error;\n            }\n          }\n        });\n\n        if (model.filenameExtension === 'txt') {\n          const parser = parse({\n            columns: true,\n            relax_quotes: true,\n            trim: true,\n            skip_empty_lines: true,\n            ...task.csvOptions,\n          });\n\n          let lines: { [x: string]: SqlValue; geojson?: string }[] = [];\n\n          parser.on('readable', () => {\n            try {\n              let record;\n\n              while ((record = parser.read())) {\n                totalLineCount += 1;\n                lines.push(formatGtfsLine(record, model, totalLineCount));\n\n                if (lines.length >= BATCH_SIZE) {\n                  insertLines(lines);\n                  lines = [];\n\n                  task.log(\n                    `Importing - ${filename} - ${totalLineCount} lines imported\\r`,\n                    true,\n                  );\n                }\n              }\n            } catch (error: unknown) {\n              if (task.ignoreErrors) {\n                const errorMessage =\n                  error instanceof Error ? error.message : String(error);\n                task.logError(`Error processing ${filename}: ${errorMessage}`);\n                resolve();\n              } else {\n                reject(error);\n              }\n            }\n          });\n\n          parser.on('end', () => {\n            try {\n              if (lines.length > 0) {\n                try {\n                  insertLines(lines);\n                } catch (error: unknown) {\n                  if (task.ignoreErrors) {\n                    const errorMessage =\n                      error instanceof Error ? error.message : String(error);\n                    task.logError(\n                      `Error inserting data for ${filename}: ${errorMessage}`,\n                    );\n                    resolve();\n                    return;\n                  } else {\n                    reject(error);\n                    return;\n                  }\n                }\n              }\n              task.log(\n                `Importing - ${filename} - ${totalLineCount} lines imported\\r`,\n                true,\n              );\n              resolve();\n            } catch (error: unknown) {\n              if (task.ignoreErrors) {\n                const errorMessage =\n                  error instanceof Error ? error.message : String(error);\n                task.logError(`Error finalizing ${filename}: ${errorMessage}`);\n                resolve();\n              } else {\n                reject(error);\n              }\n            }\n          });\n\n          parser.on('error', (error: unknown) => {\n            if (task.ignoreErrors) {\n              const errorMessage =\n                error instanceof Error ? error.message : String(error);\n              task.logError(`Parser error for ${filename}: ${errorMessage}`);\n              resolve();\n            } else {\n              reject(error);\n            }\n          });\n\n          createReadStream(filepath).pipe(stripBomStream()).pipe(parser);\n        } else if (model.filenameExtension === 'geojson') {\n          readFile(filepath, 'utf8')\n            .then((data) => {\n              if (isValidJSON(data) === false) {\n                if (task.ignoreErrors) {\n                  task.logError(`Invalid JSON in ${filename}`);\n                  resolve();\n                  return;\n                } else {\n                  reject(new Error(`Invalid JSON in ${filename}`));\n                  return;\n                }\n              }\n              totalLineCount += 1;\n              const line = formatGtfsLine(\n                { geojson: data },\n                model,\n                totalLineCount,\n              );\n              try {\n                insertLines([line]);\n                task.log(\n                  `Importing - ${filename} - ${totalLineCount} lines imported\\r`,\n                  true,\n                );\n                resolve();\n              } catch (error: unknown) {\n                if (task.ignoreErrors) {\n                  const errorMessage =\n                    error instanceof Error ? error.message : String(error);\n                  task.logError(\n                    `Error inserting data for ${filename}: ${errorMessage}`,\n                  );\n                  resolve();\n                } else {\n                  reject(error);\n                }\n              }\n            })\n            .catch((error: unknown) => {\n              if (task.ignoreErrors) {\n                const errorMessage =\n                  error instanceof Error ? error.message : String(error);\n                task.logError(`Error reading ${filename}: ${errorMessage}`);\n                resolve();\n              } else {\n                reject(error);\n              }\n            });\n        } else {\n          if (task.ignoreErrors) {\n            task.logError(\n              `Unsupported file type: ${model.filenameExtension} for ${filename}`,\n            );\n            resolve();\n          } else {\n            reject(\n              new Error(`Unsupported file type: ${model.filenameExtension}`),\n            );\n          }\n        }\n      }),\n  );\n  task.log(`Static GTFS import complete`);\n};\n\n/**\n * Function to import GTFS files into the database\n *\n * @param initialConfig\n */\nexport async function importGtfs(initialConfig: Config): Promise<void> {\n  // Start timer\n  const startTime = process.hrtime.bigint();\n\n  const config = setDefaultConfig(initialConfig);\n  validateConfigForImport(config);\n\n  try {\n    const db = openDb(config);\n    const agencyCount = config.agencies.length;\n\n    log(config)(\n      `Starting GTFS import for ${pluralize('file', 'files', agencyCount)} using SQLite database at ${config.sqlitePath}`,\n    );\n\n    createGtfsTables(db);\n\n    await mapSeries(config.agencies, async (agency: ConfigAgency) => {\n      try {\n        const tempPath = temporaryDirectory();\n\n        const task = {\n          exclude: agency.exclude,\n          headers: agency.headers,\n          realtimeAlerts: agency.realtimeAlerts,\n          realtimeTripUpdates: agency.realtimeTripUpdates,\n          realtimeVehiclePositions: agency.realtimeVehiclePositions,\n          downloadDir: tempPath,\n          downloadTimeout: config.downloadTimeout,\n          gtfsRealtimeExpirationSeconds: config.gtfsRealtimeExpirationSeconds,\n          csvOptions: config.csvOptions || {},\n          ignoreDuplicates: config.ignoreDuplicates,\n          ignoreErrors: config.ignoreErrors,\n          sqlitePath: config.sqlitePath,\n          prefix: agency.prefix,\n          currentTimestamp: Math.floor(Date.now() / 1000),\n          log: log(config),\n          logWarning: logWarning(config),\n          logError: logError(config),\n        };\n\n        if ('url' in agency) {\n          Object.assign(task, { url: agency.url });\n\n          await downloadGtfsFiles(task);\n        } else {\n          Object.assign(task, {\n            path: agency.path,\n          });\n        }\n\n        await extractGtfsFiles(task);\n        await importGtfsFiles(db, task);\n        await updateGtfsRealtimeData(task);\n\n        await rm(tempPath, { recursive: true });\n      } catch (error: unknown) {\n        if (config.ignoreErrors) {\n          const errorMessage =\n            error instanceof Error ? error.message : String(error);\n          logError(config)(errorMessage);\n        } else {\n          throw error;\n        }\n      }\n    });\n\n    log(config)(`Creating DB indexes`);\n    createGtfsIndexes(db);\n\n    const endTime = process.hrtime.bigint();\n    const elapsedSeconds = Number(endTime - startTime) / 1_000_000_000;\n\n    log(config)(\n      `Completed GTFS import in ${elapsedSeconds.toFixed(1)} seconds\\n`,\n    );\n  } catch (error: unknown) {\n    if ((error as Error & { code?: string }).code === 'SQLITE_CANTOPEN') {\n      logError(config)(\n        `Unable to open sqlite database \"${config.sqlitePath}\" defined as \\`sqlitePath\\` config.json. Ensure the parent directory exists or remove \\`sqlitePath\\` from config.json.`,\n      );\n    }\n    throw error;\n  }\n}\n","export const tripUpdates = {\n  filenameBase: 'trip_updates',\n  extension: 'gtfs-realtime',\n  schema: [\n    {\n      name: 'id',\n      type: 'text',\n      required: true,\n      primary: true,\n      index: true,\n      source: 'id',\n      prefix: true,\n    },\n    {\n      name: 'vehicle_id',\n      type: 'text',\n      index: true,\n      source: 'tripUpdate.vehicle.id',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'trip_id',\n      type: 'text',\n      index: true,\n      source: 'tripUpdate.trip.tripId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'trip_start_time',\n      type: 'text',\n      source: 'tripUpdate.trip.startTime',\n      default: null,\n    },\n    {\n      name: 'direction_id',\n      type: 'integer',\n      source: 'tripUpdate.trip.directionId',\n      default: null,\n    },\n    {\n      name: 'route_id',\n      type: 'text',\n      index: true,\n      source: 'tripUpdate.trip.routeId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'start_date',\n      type: 'text',\n      source: 'tripUpdate.trip.startDate',\n      default: null,\n    },\n    {\n      name: 'timestamp',\n      type: 'text',\n      source: 'tripUpdate.timestamp',\n      default: null,\n    },\n    {\n      name: 'schedule_relationship',\n      type: 'text',\n      source: 'tripUpdate.trip.scheduleRelationship',\n      default: null,\n    },\n    {\n      name: 'created_timestamp',\n      type: 'integer',\n      required: true,\n    },\n    {\n      name: 'expiration_timestamp',\n      type: 'integer',\n      required: true,\n    },\n  ],\n};\n","export const stopTimeUpdates = {\n  filenameBase: 'stop_time_updates',\n  extension: 'gtfs-realtime',\n  schema: [\n    {\n      name: 'trip_id',\n      type: 'text',\n      index: true,\n      source: 'parent.tripUpdate.trip.tripId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'trip_start_time',\n      type: 'text',\n      source: 'parent.tripUpdate.trip.startTime',\n      default: null,\n    },\n    {\n      name: 'direction_id',\n      type: 'integer',\n      source: 'parent.tripUpdate.trip.directionId',\n      default: null,\n    },\n    {\n      name: 'route_id',\n      type: 'text',\n      index: true,\n      source: 'parent.tripUpdate.trip.routeId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'stop_id',\n      type: 'text',\n      index: true,\n      source: 'stopId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'stop_sequence',\n      type: 'integer',\n      source: 'stopSequence',\n      default: null,\n    },\n    {\n      name: 'arrival_delay',\n      type: 'integer',\n      source: 'arrival.delay',\n      default: null,\n    },\n    {\n      name: 'departure_delay',\n      type: 'integer',\n      source: 'departure.delay',\n      default: null,\n    },\n    {\n      name: 'departure_timestamp',\n      type: 'text',\n      source: 'departure.time',\n      default: null,\n    },\n    {\n      name: 'arrival_timestamp',\n      type: 'text',\n      source: 'arrival.time',\n      default: null,\n    },\n    {\n      name: 'schedule_relationship',\n      type: 'text',\n      source: 'scheduleRelationship',\n      default: null,\n    },\n    {\n      name: 'created_timestamp',\n      type: 'integer',\n      required: true,\n    },\n    {\n      name: 'expiration_timestamp',\n      type: 'integer',\n      required: true,\n    },\n  ],\n};\n","export const vehiclePositions = {\n  filenameBase: 'vehicle_positions',\n  extension: 'gtfs-realtime',\n  schema: [\n    {\n      name: 'id',\n      type: 'text',\n      required: true,\n      primary: true,\n      index: true,\n      source: 'id',\n      prefix: true,\n    },\n    {\n      name: 'bearing',\n      type: 'real',\n      source: 'vehicle.position.bearing',\n      default: null,\n    },\n    {\n      name: 'latitude',\n      type: 'real',\n      min: -90,\n      max: 90,\n      source: 'vehicle.position.latitude',\n      default: null,\n    },\n    {\n      name: 'longitude',\n      type: 'real',\n      source: 'vehicle.position.longitude',\n      min: -180,\n      max: 180,\n      default: null,\n    },\n    {\n      name: 'speed',\n      type: 'real',\n      min: 0,\n      source: 'vehicle.position.speed',\n      default: null,\n    },\n    {\n      name: 'current_stop_sequence',\n      type: 'integer',\n      source: 'vehicle.currentStopSequence',\n      default: null,\n    },\n    {\n      name: 'trip_id',\n      type: 'text',\n      index: true,\n      source: 'vehicle.trip.tripId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'trip_start_date',\n      type: 'text',\n      index: true,\n      source: 'vehicle.trip.startDate',\n      default: null,\n    },\n    {\n      name: 'trip_start_time',\n      type: 'text',\n      index: true,\n      source: 'vehicle.trip.startTime',\n      default: null,\n    },\n    {\n      name: 'congestion_level',\n      type: 'text',\n      source: 'vehicle.congestionLevel',\n      default: null,\n    },\n    {\n      name: 'occupancy_status',\n      type: 'text',\n      source: 'vehicle.occupancyStatus',\n      default: null,\n    },\n    {\n      name: 'occupancy_percentage',\n      type: 'integer',\n      source: 'vehicle.occupancyPercentage',\n      default: null,\n    },\n    {\n      name: 'vehicle_stop_status',\n      type: 'text',\n      source: 'vehicle.vehicleStopStatus',\n      default: null,\n    },\n    {\n      name: 'vehicle_id',\n      type: 'text',\n      index: true,\n      source: 'vehicle.vehicle.id',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'vehicle_label',\n      type: 'text',\n      source: 'vehicle.vehicle.label',\n      default: null,\n    },\n    {\n      name: 'vehicle_license_plate',\n      type: 'text',\n      source: 'vehicle.vehicle.licensePlate',\n      default: null,\n    },\n    {\n      name: 'vehicle_wheelchair_accessible',\n      type: 'text',\n      source: 'vehicle.vehicle.wheelchairAccessible',\n      default: null,\n    },\n    {\n      name: 'timestamp',\n      type: 'text',\n      source: 'vehicle.timestamp',\n      default: null,\n    },\n    {\n      name: 'created_timestamp',\n      type: 'integer',\n      required: true,\n    },\n    {\n      name: 'expiration_timestamp',\n      type: 'integer',\n      required: true,\n    },\n  ],\n};\n","export const serviceAlerts = {\n  filenameBase: 'service_alerts',\n  extension: 'gtfs-realtime',\n  schema: [\n    {\n      name: 'id',\n      type: 'text',\n      required: true,\n      primary: true,\n      index: true,\n      source: 'id',\n      prefix: true,\n    },\n    {\n      name: 'active_period',\n      type: 'json',\n      source: 'alert.activePeriod',\n    },\n    {\n      name: 'cause',\n      type: 'text',\n      source: 'alert.cause',\n    },\n    {\n      name: 'effect',\n      type: 'text',\n      source: 'alert.effect',\n    },\n    {\n      name: 'url',\n      type: 'text',\n      source: 'alert.url.translation[0].text',\n      default: '',\n    },\n    {\n      name: 'start_time',\n      type: 'text',\n      required: true,\n      source: 'alert.activePeriod[0].start',\n      default: '',\n    },\n    {\n      name: 'end_time',\n      type: 'text',\n      required: true,\n      source: 'alert.activePeriod[0].end',\n      default: '',\n    },\n    {\n      name: 'header_text',\n      type: 'text',\n      required: true,\n      source: 'alert.headerText.translation[0].text',\n      default: '',\n    },\n    {\n      name: 'description_text',\n      type: 'text',\n      required: true,\n      source: 'alert.descriptionText.translation[0].text',\n      default: '',\n    },\n    {\n      name: 'tts_header_text',\n      type: 'text',\n      source: 'alert.ttsHeaderText.translation[0].text',\n    },\n    {\n      name: 'tts_description_text',\n      type: 'text',\n      source: 'alert.ttsDescriptionText.translation[0].text',\n    },\n    {\n      name: 'severity_level',\n      type: 'text',\n      source: 'alert.severityLevel',\n    },\n    {\n      name: 'created_timestamp',\n      type: 'integer',\n      required: true,\n    },\n    {\n      name: 'expiration_timestamp',\n      type: 'integer',\n      required: true,\n    },\n  ],\n};\n","export const serviceAlertInformedEntities = {\n  filenameBase: 'service_alert_informed_entities',\n  extension: 'gtfs-realtime',\n  schema: [\n    {\n      name: 'alert_id',\n      type: 'text',\n      required: true,\n      primary: true,\n      source: 'parent.id',\n      prefix: true,\n    },\n    {\n      name: 'stop_id',\n      type: 'text',\n      index: true,\n      source: 'stopId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'route_id',\n      type: 'text',\n      index: true,\n      source: 'routeId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'route_type',\n      type: 'integer',\n      index: true,\n      source: 'routeType',\n      default: null,\n    },\n    {\n      name: 'trip_id',\n      type: 'text',\n      index: true,\n      source: 'trip.tripId',\n      default: null,\n      prefix: true,\n    },\n    {\n      name: 'direction_id',\n      type: 'integer',\n      index: true,\n      source: 'directionId',\n      default: null,\n    },\n    {\n      name: 'created_timestamp',\n      type: 'integer',\n      required: true,\n    },\n    {\n      name: 'expiration_timestamp',\n      type: 'integer',\n      required: true,\n    },\n  ],\n};\n","import fs from 'fs';\n\nimport Database from 'better-sqlite3';\n\nimport { untildify } from './file-utils.ts';\n\nconst dbs: { [key: string]: Database.Database } = {};\n\nfunction setupDb(sqlitePath: string) {\n  const db = new Database(untildify(sqlitePath));\n  db.pragma('journal_mode = OFF');\n  db.pragma('synchronous = OFF');\n  db.pragma('temp_store = MEMORY');\n  dbs[sqlitePath] = db;\n\n  return db;\n}\n\nexport function openDb(\n  config: { db?: Database.Database; sqlitePath?: string } | null = null,\n): Database.Database {\n  // If config is passed, use that to open or return db\n  if (config) {\n    const { sqlitePath = ':memory:', db } = config;\n\n    // If db connection is passed, use it\n    if (db) {\n      return db;\n    }\n\n    // If db connection already exists, return it\n    if (dbs[sqlitePath]) {\n      return dbs[sqlitePath];\n    }\n\n    // If no db connection exists, create it\n    return setupDb(sqlitePath);\n  }\n\n  // If no db connection exists, create a new one in memory\n  if (Object.keys(dbs).length === 0) {\n    return setupDb(':memory:');\n  }\n\n  // If only one db connection already exists, use it\n  if (Object.keys(dbs).length === 1) {\n    const filename = Object.keys(dbs)[0];\n    return dbs[filename];\n  }\n\n  if (Object.keys(dbs).length > 1) {\n    throw new Error(\n      'Multiple databases open, please specify which one to use.',\n    );\n  }\n\n  throw new Error('Unable to find database connection.');\n}\n\nexport function closeDb(db: Database.Database | null = null): void {\n  if (Object.keys(dbs).length === 0) {\n    throw new Error(\n      'No database connection. Call `openDb(config)` before using any methods.',\n    );\n  }\n\n  if (!db) {\n    if (Object.keys(dbs).length > 1) {\n      throw new Error(\n        'Multiple database connections. Pass the db you want to close as a parameter to `closeDb`.',\n      );\n    }\n\n    db = dbs[Object.keys(dbs)[0]];\n  }\n\n  db.close();\n  delete dbs[db.name];\n}\n\nexport function deleteDb(db: Database.Database | null = null): void {\n  if (Object.keys(dbs).length === 0) {\n    throw new Error(\n      'No database connection. Call `openDb(config)` before using any methods.',\n    );\n  }\n\n  if (!db) {\n    if (Object.keys(dbs).length > 1) {\n      throw new Error(\n        'Multiple database connections. Pass the db you want to delete as a parameter to `deleteDb`.',\n      );\n    }\n\n    db = dbs[Object.keys(dbs)[0]];\n  }\n\n  db.close();\n\n  fs.unlinkSync(db.name);\n\n  delete dbs[db.name];\n}\n","import {\n  cloneDeep,\n  compact,\n  filter,\n  groupBy,\n  last,\n  omit,\n  sortBy,\n  omitBy,\n} from 'lodash-es';\nimport { feature, featureCollection } from '@turf/helpers';\nimport { Shape, Stop } from '../types/global_interfaces.ts';\n\n/** Represents a GeoJSON coordinate pair [longitude, latitude] */\ntype Position = [number, number];\n\n/**\n * Validates if a string is valid JSON\n * @param {string} string - The string to validate as JSON\n * @returns {boolean} True if string is valid JSON, false otherwise\n * @example\n * isValidJSON('{\"key\": \"value\"}') // returns true\n * isValidJSON('invalid json') // returns false\n */\nexport function isValidJSON(string: string): boolean {\n  try {\n    JSON.parse(string);\n    return true;\n  } catch {\n    return false;\n  }\n}\n\n/**\n * Validates if an array of positions forms a valid LineString\n * @param {Position[]} [lineString] - Array of coordinate pairs\n * @returns {boolean} True if lineString is valid, false otherwise\n */\nfunction isValidLineString(lineString?: Position[]): boolean {\n  if (!lineString || lineString.length <= 1) {\n    return false;\n  }\n\n  // Reject linestrings with two identical points\n  if (lineString.length === 2) {\n    const [[x1, y1], [x2, y2]] = lineString;\n    return !(x1 === x2 && y1 === y2);\n  }\n\n  return true;\n}\n\n/**\n * Consolidates shape groups into unique line segments\n * @param {Shape[][]} shapeGroups - Array of shape point groups\n * @returns {Position[][]} Array of consolidated line strings\n */\nfunction consolidateShapes(shapeGroups: Shape[][]): Position[][] {\n  const keys = new Set<string>();\n  const segmentsArray = shapeGroups.map((shapes) =>\n    shapes.reduce<Position[][]>((memo, point, idx) => {\n      if (idx > 0) {\n        const prevPoint = shapes[idx - 1];\n        memo.push([\n          [prevPoint.shape_pt_lon, prevPoint.shape_pt_lat],\n          [point.shape_pt_lon, point.shape_pt_lat],\n        ]);\n      }\n      return memo;\n    }, []),\n  );\n\n  const consolidatedLineStrings: Position[][] = [];\n\n  for (const segments of segmentsArray) {\n    consolidatedLineStrings.push([]);\n\n    for (const segment of segments) {\n      const key1 = segment.flat().join(',');\n      const key2 = segment.reverse().flat().join(',');\n      const currentLine = last(consolidatedLineStrings);\n\n      if (!currentLine || keys.has(key1) || keys.has(key2)) {\n        consolidatedLineStrings.push([]);\n        continue;\n      }\n\n      if (currentLine.length === 0) {\n        currentLine.push(segment[0]);\n      }\n      currentLine.push(segment[1]);\n      keys.add(key1);\n      keys.add(key2);\n    }\n  }\n\n  return filter(consolidatedLineStrings, isValidLineString);\n}\n\n/**\n * Formats a color string to hex format\n * @param {string | null | undefined} color - Color string to format\n * @returns {string | undefined} Formatted hex color or undefined\n * @example\n * formatHexColor('FF0000') // returns '#FF0000'\n */\nfunction formatHexColor(color: string | null | undefined): string | undefined {\n  if (!color) return undefined;\n  return `#${color}`;\n}\n\n/**\n * Formats properties object by cleaning null values and formatting colors\n * @param {Record<string, unknown>} properties - Properties object to format\n * @returns {Record<string, unknown>} Formatted properties object\n */\nfunction formatProperties(\n  properties: Record<string, unknown>,\n): Record<string, unknown> {\n  const formattedProperties = cloneDeep(\n    omitBy(properties, (value) => value == null),\n  );\n\n  const formattedRouteColor = formatHexColor(properties.route_color);\n  const formattedRouteTextColor = formatHexColor(properties.route_text_color);\n\n  if (formattedRouteColor) {\n    formattedProperties.route_color = formattedRouteColor;\n  }\n\n  if (formattedRouteTextColor) {\n    formattedProperties.route_text_color = formattedRouteTextColor;\n  }\n\n  if (properties.routes && Array.isArray(properties.routes)) {\n    formattedProperties.routes = properties.routes.map(\n      (route: Record<string, unknown>) => formatProperties(route),\n    );\n  }\n\n  return formattedProperties;\n}\n\n/**\n * Converts GTFS shapes to GeoJSON Feature\n * @param {Shape[]} shapes - Array of GTFS shapes\n * @param {Record<string, any>} [properties={}] - Properties to add to the feature\n * @returns {Feature} GeoJSON Feature with MultiLineString geometry\n */\nexport function shapesToGeoJSONFeature(\n  shapes: Shape[],\n  properties: Record<string, unknown> = {},\n) {\n  const shapeGroups = Object.values(groupBy(shapes, 'shape_id')).map(\n    (shapeGroup) => sortBy(shapeGroup, 'shape_pt_sequence'),\n  );\n\n  const lineStrings = consolidateShapes(shapeGroups);\n\n  return feature(\n    {\n      type: 'MultiLineString',\n      coordinates: lineStrings,\n    },\n    formatProperties(properties),\n  );\n}\n\n/**\n * Converts GTFS stops to GeoJSON FeatureCollection\n * @param {Stop[]} stops - Array of GTFS stops\n * @returns {FeatureCollection} GeoJSON FeatureCollection of Point features\n */\nexport function stopsToGeoJSONFeatureCollection(stops: Stop[]) {\n  const features = compact(\n    stops.map((stop) => {\n      if (!stop.stop_lon || !stop.stop_lat) {\n        return undefined;\n      }\n\n      return feature(\n        {\n          type: 'Point',\n          coordinates: [stop.stop_lon, stop.stop_lat],\n        },\n        formatProperties(omit(stop, ['stop_lat', 'stop_lon'])),\n      );\n    }),\n  );\n\n  return featureCollection(features);\n}\n","import GtfsRealtimeBindings from 'gtfs-realtime-bindings';\nimport mapSeries from 'promise-map-series';\nimport { get } from 'lodash-es';\nimport Database from 'better-sqlite3';\n\nimport * as models from '../models/models.ts';\nimport { openDb } from './db.ts';\nimport { log, logError, logWarning } from './log-utils.ts';\nimport {\n  convertLongTimeToDate,\n  applyPrefixToValue,\n  pluralize,\n  setDefaultConfig,\n  validateConfigForImport,\n} from './utils.ts';\n\nimport {\n  Config,\n  ConfigAgency,\n  ModelColumn,\n  Model,\n} from '../types/global_interfaces.ts';\n\ninterface RealtimeUrlConfig {\n  url: string;\n  headers?: Record<string, string>;\n}\n\ninterface GtfsRealtimeTask {\n  realtimeAlerts?: RealtimeUrlConfig;\n  realtimeTripUpdates?: RealtimeUrlConfig;\n  realtimeVehiclePositions?: RealtimeUrlConfig;\n  downloadTimeout?: number;\n  gtfsRealtimeExpirationSeconds: number;\n  ignoreErrors: boolean;\n  sqlitePath: string;\n  prefix?: string;\n  currentTimestamp: number;\n  log: (message: string, newLine?: boolean) => void;\n  logWarning: (message: string) => void;\n  logError: (message: string) => void;\n}\n\ninterface ProcessedEntity {\n  id: string;\n  alert?: any; // eslint-disable-line @typescript-eslint/no-explicit-any\n  tripUpdate?: any; // eslint-disable-line @typescript-eslint/no-explicit-any\n  vehicle?: any; // eslint-disable-line @typescript-eslint/no-explicit-any\n}\n\ninterface RealtimeData {\n  entity: ProcessedEntity[];\n}\n\ninterface ProcessingResult {\n  recordCount: number;\n  errorCount: number;\n}\n\ninterface BatchProcessor<T> {\n  (batch: T[]): Promise<ProcessingResult>;\n}\n\nconst BATCH_SIZE = 1000;\nconst MAX_RETRIES = 3;\nconst RETRY_DELAY = 1000;\n\n/**\n * Prepares a field value for database insertion\n */\nfunction prepareRealtimeFieldValue(\n  entity: any, // eslint-disable-line @typescript-eslint/no-explicit-any\n  column: ModelColumn,\n  task: GtfsRealtimeTask,\n) {\n  if (column.name === 'created_timestamp') {\n    return task.currentTimestamp;\n  }\n\n  if (column.name === 'expiration_timestamp') {\n    return task.currentTimestamp + task.gtfsRealtimeExpirationSeconds;\n  }\n\n  const baseValue =\n    column.source === undefined\n      ? column.default\n      : get(entity, column.source, column.default);\n\n  const timeAdjustedValue = baseValue?.__isLong__\n    ? convertLongTimeToDate(baseValue)\n    : baseValue;\n\n  const prefixedValue = applyPrefixToValue(\n    timeAdjustedValue,\n    column.prefix,\n    task.prefix,\n  );\n\n  return column.type === 'json' ? JSON.stringify(prefixedValue) : prefixedValue;\n}\n\n/**\n * Creates a prepared statement for a model\n */\nfunction createPreparedStatement(db: Database.Database, model: Model) {\n  const columns = model.schema.map((column: ModelColumn) => column.name);\n  const placeholders = model.schema.map(() => '?').join(', ');\n\n  return db.prepare(\n    `REPLACE INTO ${model.filenameBase} (${columns.join(', ')}) VALUES (${placeholders})`,\n  );\n}\n\n/**\n * Processes entities in batches\n */\nasync function processBatch<T>(\n  items: T[],\n  batchSize: number,\n  processor: BatchProcessor<T>,\n): Promise<ProcessingResult> {\n  let totalRecordCount = 0;\n  let totalErrorCount = 0;\n\n  for (let i = 0; i < items.length; i += batchSize) {\n    const batch = items.slice(i, i + batchSize);\n    try {\n      const result = await processor(batch);\n      totalRecordCount += result.recordCount;\n      totalErrorCount += result.errorCount;\n    } catch (error: unknown) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      totalErrorCount += batch.length;\n      console.error(`Batch processing error: ${errorMessage}`);\n    }\n  }\n\n  return { recordCount: totalRecordCount, errorCount: totalErrorCount };\n}\n\n/**\n * Fetches GTFS Realtime data\n */\nasync function fetchGtfsRealtimeData(\n  type: 'alerts' | 'tripupdates' | 'vehiclepositions',\n  task: GtfsRealtimeTask,\n): Promise<RealtimeData | null> {\n  const urlConfig = getUrlConfig(type, task);\n\n  if (!urlConfig) {\n    return null;\n  }\n\n  task.log(`Importing - GTFS-Realtime from ${urlConfig.url}`);\n\n  for (let attempt = 1; attempt <= MAX_RETRIES; attempt++) {\n    try {\n      const response = await fetch(urlConfig.url, {\n        method: 'GET',\n        headers: {\n          ...(urlConfig.headers ?? {}),\n          'Accept-Encoding': 'gzip',\n        },\n        signal: task.downloadTimeout\n          ? AbortSignal.timeout(task.downloadTimeout)\n          : undefined,\n      });\n\n      if (response.status !== 200) {\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n      }\n\n      const buffer = await response.arrayBuffer();\n      const message = GtfsRealtimeBindings.transit_realtime.FeedMessage.decode(\n        new Uint8Array(buffer),\n      );\n\n      const feedMessage =\n        GtfsRealtimeBindings.transit_realtime.FeedMessage.toObject(message, {\n          enums: String,\n          longs: String,\n          bytes: String,\n          defaults: false,\n          arrays: true,\n          objects: true,\n          oneofs: true,\n        }) as RealtimeData;\n\n      return feedMessage;\n    } catch (error: unknown) {\n      const errorMessage =\n        error instanceof Error ? error.message : String(error);\n      if (attempt === MAX_RETRIES) {\n        if (task.ignoreErrors) {\n          task.logError(\n            `Failed to fetch ${type} after ${MAX_RETRIES} attempts: ${errorMessage}`,\n          );\n          return null;\n        }\n        throw error;\n      }\n\n      task.logWarning(`Attempt ${attempt} failed for ${type}: ${errorMessage}`);\n      await new Promise((resolve) =>\n        setTimeout(resolve, RETRY_DELAY * attempt),\n      );\n    }\n  }\n\n  return null;\n}\n\n/**\n * Gets URL configuration for a specific realtime type\n */\nfunction getUrlConfig(\n  type: 'alerts' | 'tripupdates' | 'vehiclepositions',\n  task: GtfsRealtimeTask,\n): RealtimeUrlConfig | undefined {\n  switch (type) {\n    case 'alerts':\n      return task.realtimeAlerts;\n    case 'tripupdates':\n      return task.realtimeTripUpdates;\n    case 'vehiclepositions':\n      return task.realtimeVehiclePositions;\n    default:\n      return undefined;\n  }\n}\n\n/**\n * Creates a processor for service alerts\n */\nfunction createServiceAlertsProcessor(\n  db: Database.Database,\n  task: GtfsRealtimeTask,\n): BatchProcessor<ProcessedEntity> {\n  const alertStmt = createPreparedStatement(db, models.serviceAlerts as Model);\n  const informedEntityStmt = createPreparedStatement(\n    db,\n    models.serviceAlertInformedEntities as Model,\n  );\n\n  return async (batch: ProcessedEntity[]): Promise<ProcessingResult> => {\n    let recordCount = 0;\n    let errorCount = 0;\n\n    db.transaction(() => {\n      for (const entity of batch) {\n        try {\n          // Process main alert\n          const alertValues = (\n            models.serviceAlerts.schema as ModelColumn[]\n          ).map((column) => prepareRealtimeFieldValue(entity, column, task));\n          alertStmt.run(alertValues);\n          recordCount++;\n\n          // Process informed entities\n          if (entity.alert?.informedEntity?.length) {\n            for (const informedEntity of entity.alert.informedEntity) {\n              informedEntity.parent = entity;\n              const entityValues = (\n                models.serviceAlertInformedEntities.schema as ModelColumn[]\n              ).map((column) =>\n                prepareRealtimeFieldValue(informedEntity, column, task),\n              );\n              informedEntityStmt.run(entityValues);\n              recordCount++;\n            }\n          }\n        } catch (error: unknown) {\n          const errorMessage =\n            error instanceof Error ? error.message : String(error);\n          errorCount++;\n          task.logWarning(`Alert processing error: ${errorMessage}`);\n        }\n      }\n    })();\n\n    return { recordCount, errorCount };\n  };\n}\n\n/**\n * Creates a processor for trip updates\n */\nfunction createTripUpdatesProcessor(\n  db: Database.Database,\n  task: GtfsRealtimeTask,\n): BatchProcessor<ProcessedEntity> {\n  const tripUpdateStmt = createPreparedStatement(\n    db,\n    models.tripUpdates as Model,\n  );\n  const stopTimeStmt = createPreparedStatement(\n    db,\n    models.stopTimeUpdates as Model,\n  );\n\n  return async (batch: ProcessedEntity[]): Promise<ProcessingResult> => {\n    let recordCount = 0;\n    let errorCount = 0;\n\n    db.transaction(() => {\n      for (const entity of batch) {\n        try {\n          // Process main trip update\n          const tripUpdateValues = (\n            models.tripUpdates.schema as ModelColumn[]\n          ).map((column) => prepareRealtimeFieldValue(entity, column, task));\n          tripUpdateStmt.run(tripUpdateValues);\n          recordCount++;\n\n          // Process stop time updates\n          if (entity.tripUpdate?.stopTimeUpdate?.length) {\n            for (const stopTimeUpdate of entity.tripUpdate.stopTimeUpdate) {\n              stopTimeUpdate.parent = entity;\n              const stopTimeValues = (\n                models.stopTimeUpdates.schema as ModelColumn[]\n              ).map((column) =>\n                prepareRealtimeFieldValue(stopTimeUpdate, column, task),\n              );\n              stopTimeStmt.run(stopTimeValues);\n              recordCount++;\n            }\n          }\n        } catch (error: unknown) {\n          const errorMessage =\n            error instanceof Error ? error.message : String(error);\n          errorCount++;\n          task.logWarning(`Trip update processing error: ${errorMessage}`);\n        }\n      }\n    })();\n\n    return { recordCount, errorCount };\n  };\n}\n\n/**\n * Creates a processor for vehicle positions\n */\nfunction createVehiclePositionsProcessor(\n  db: Database.Database,\n  task: GtfsRealtimeTask,\n): BatchProcessor<ProcessedEntity> {\n  const vehiclePositionStmt = createPreparedStatement(\n    db,\n    models.vehiclePositions as Model,\n  );\n\n  return async (batch: ProcessedEntity[]): Promise<ProcessingResult> => {\n    let recordCount = 0;\n    let errorCount = 0;\n\n    db.transaction(() => {\n      for (const entity of batch) {\n        try {\n          const fieldValues = (\n            models.vehiclePositions.schema as ModelColumn[]\n          ).map((column) => prepareRealtimeFieldValue(entity, column, task));\n          vehiclePositionStmt.run(fieldValues);\n          recordCount++;\n        } catch (error: unknown) {\n          const errorMessage =\n            error instanceof Error ? error.message : String(error);\n          errorCount++;\n          task.logWarning(`Vehicle position processing error: ${errorMessage}`);\n        }\n      }\n    })();\n\n    return { recordCount, errorCount };\n  };\n}\n\n/**\n * Removes expired GTFS-Realtime data\n */\nfunction removeExpiredRealtimeData(config: Config): void {\n  const db = openDb(config);\n\n  log(config)(`Removing expired GTFS-Realtime data`);\n\n  db.transaction(() => {\n    const tables = [\n      'vehicle_positions',\n      'trip_updates',\n      'stop_time_updates',\n      'service_alerts',\n      'service_alert_informed_entities',\n    ];\n\n    for (const table of tables) {\n      db.prepare(\n        `DELETE FROM ${table} WHERE expiration_timestamp <= strftime('%s','now')`,\n      ).run();\n    }\n  })();\n\n  log(config)(`Removed expired GTFS-Realtime data\\r`, true);\n}\n\n/**\n * Updates GTFS Realtime data\n */\nexport async function updateGtfsRealtimeData(\n  task: GtfsRealtimeTask,\n): Promise<void> {\n  if (\n    !task.realtimeAlerts &&\n    !task.realtimeTripUpdates &&\n    !task.realtimeVehiclePositions\n  ) {\n    return;\n  }\n\n  // Download all data types in parallel\n  const [alertsData, tripUpdatesData, vehiclePositionsData] = await Promise.all(\n    [\n      task.realtimeAlerts?.url ? fetchGtfsRealtimeData('alerts', task) : null,\n      task.realtimeTripUpdates?.url\n        ? fetchGtfsRealtimeData('tripupdates', task)\n        : null,\n      task.realtimeVehiclePositions?.url\n        ? fetchGtfsRealtimeData('vehiclepositions', task)\n        : null,\n    ],\n  );\n\n  const db = openDb({ sqlitePath: task.sqlitePath });\n\n  const recordCounts = {\n    alerts: 0,\n    tripupdates: 0,\n    vehiclepositions: 0,\n  };\n\n  // Process each data type with batching\n  const processingPromises: Promise<void>[] = [];\n\n  if (alertsData?.entity?.length) {\n    processingPromises.push(\n      processBatch(\n        alertsData.entity,\n        BATCH_SIZE,\n        createServiceAlertsProcessor(db, task),\n      ).then((result) => {\n        recordCounts.alerts = result.recordCount;\n      }),\n    );\n  }\n\n  if (tripUpdatesData?.entity?.length) {\n    processingPromises.push(\n      processBatch(\n        tripUpdatesData.entity,\n        BATCH_SIZE,\n        createTripUpdatesProcessor(db, task),\n      ).then((result) => {\n        recordCounts.tripupdates = result.recordCount;\n      }),\n    );\n  }\n\n  if (vehiclePositionsData?.entity?.length) {\n    processingPromises.push(\n      processBatch(\n        vehiclePositionsData.entity,\n        BATCH_SIZE,\n        createVehiclePositionsProcessor(db, task),\n      ).then((result) => {\n        recordCounts.vehiclepositions = result.recordCount;\n      }),\n    );\n  }\n\n  // Wait for all processing to complete\n  await Promise.all(processingPromises);\n\n  task.log(\n    `GTFS-Realtime import complete: ${recordCounts.alerts} alerts, ${recordCounts.tripupdates} trip updates, ${recordCounts.vehiclepositions} vehicle positions`,\n  );\n}\n\n/**\n * Main function to update GTFS Realtime data\n */\nexport async function updateGtfsRealtime(initialConfig: Config): Promise<void> {\n  const config = setDefaultConfig(initialConfig);\n  validateConfigForImport(config);\n\n  try {\n    openDb(config);\n\n    const agencyCount = config.agencies.length;\n    log(config)(\n      `Starting GTFS-Realtime refresh for ${pluralize(\n        'agency',\n        'agencies',\n        agencyCount,\n      )} using SQLite database at ${config.sqlitePath}`,\n    );\n\n    removeExpiredRealtimeData(config);\n\n    await mapSeries(config.agencies, async (agency: ConfigAgency) => {\n      try {\n        const task: GtfsRealtimeTask = {\n          realtimeAlerts: agency.realtimeAlerts,\n          realtimeTripUpdates: agency.realtimeTripUpdates,\n          realtimeVehiclePositions: agency.realtimeVehiclePositions,\n          downloadTimeout: config.downloadTimeout,\n          gtfsRealtimeExpirationSeconds: config.gtfsRealtimeExpirationSeconds,\n          ignoreErrors: config.ignoreErrors,\n          sqlitePath: config.sqlitePath,\n          prefix: agency.prefix,\n          currentTimestamp: Math.floor(Date.now() / 1000),\n          log: log(config),\n          logWarning: logWarning(config),\n          logError: logError(config),\n        };\n\n        await updateGtfsRealtimeData(task);\n      } catch (error: unknown) {\n        const errorMessage =\n          error instanceof Error ? error.message : String(error);\n        if (config.ignoreErrors) {\n          logError(config)(errorMessage);\n        } else {\n          throw error;\n        }\n      }\n    });\n\n    log(config)(\n      `Completed GTFS-Realtime refresh for ${pluralize(\n        'agency',\n        'agencies',\n        agencyCount,\n      )}\\n`,\n    );\n  } catch (error: unknown) {\n    if ((error as Error & { code?: string }).code === 'SQLITE_CANTOPEN') {\n      logError(config)(\n        `Unable to open sqlite database \"${config.sqlitePath}\" defined as \\`sqlitePath\\` config.json. Ensure the parent directory exists or remove \\`sqlitePath\\` from config.json.`,\n      );\n    }\n    throw error;\n  }\n}\n","import sqlString from 'sqlstring-sqlite';\nimport Long from 'long';\nimport {\n  Config,\n  JoinOptions,\n  SqlWhere,\n  SqlValue,\n  SqlOrderBy,\n} from '../types/global_interfaces.ts';\n\n/**\n * Validates the configuration object for GTFS import\n * @param config The configuration object to validate\n * @throws Error if agencies are missing or if agency lacks both url and path\n * @returns The validated config object\n */\nexport function validateConfigForImport(config: Config) {\n  if (!config.agencies || config.agencies.length === 0) {\n    throw new Error('No `agencies` specified in config');\n  }\n\n  for (const [index, agency] of config.agencies.entries()) {\n    if (!agency.path && !agency.url) {\n      throw new Error(\n        `No Agency \\`url\\` or \\`path\\` specified in config for agency index ${index}.`,\n      );\n    }\n  }\n\n  return config;\n}\n\n/**\n * Initializes configuration with default values\n * @param initialConfig The user-provided configuration\n * @returns Merged configuration with defaults\n */\nexport function setDefaultConfig(initialConfig: Config) {\n  const defaults = {\n    sqlitePath: ':memory:',\n    ignoreDuplicates: false,\n    ignoreErrors: false,\n    gtfsRealtimeExpirationSeconds: 0,\n    verbose: true,\n    downloadTimeout: 30000,\n  };\n\n  return {\n    ...defaults,\n    ...initialConfig,\n  };\n}\n\n/**\n * Converts a Long timestamp to ISO date string\n * @param longDate Object containing high, low, and unsigned values\n * @returns ISO formatted date string\n */\nexport function convertLongTimeToDate(longDate: {\n  high: number;\n  low: number;\n  unsigned: boolean;\n}) {\n  const { high, low, unsigned } = longDate;\n  return new Date(\n    Long.fromBits(low, high, unsigned).toNumber() * 1000,\n  ).toISOString();\n}\n\n/**\n * Converts time string in HH:mm:ss format to seconds since midnight\n * @param time Time string in HH:mm:ss format\n * @returns Number of seconds since midnight, or null if invalid format\n */\nexport function calculateSecondsFromMidnight(time: string): number | null {\n  if (!time || typeof time !== 'string') {\n    return null;\n  }\n\n  const [hours, minutes, seconds] = time.split(':').map(Number);\n\n  if ([hours, minutes, seconds].some(isNaN) || minutes >= 60 || seconds >= 60) {\n    return null;\n  }\n\n  return hours * 3600 + minutes * 60 + seconds;\n}\n\n/**\n * Ensures time components have leading zeros (e.g., \"9:5:1\" -> \"09:05:01\")\n * @param time Time string in HH:mm:ss format\n * @returns Formatted time string with leading zeros, or null if invalid format\n */\nexport function padLeadingZeros(time: string) {\n  const split = time.split(':').map((d) => String(Number(d)).padStart(2, '0'));\n  if (split.length !== 3) {\n    return null;\n  }\n\n  return split.join(':');\n}\n\n/**\n * Formats SQL SELECT clause from array of field names or field mapping object\n * @param fields Array of field names or object mapping source to alias\n * @returns Formatted SELECT clause\n */\nexport function formatSelectClause(fields: string[]) {\n  if (Array.isArray(fields)) {\n    const selectItem =\n      fields.length > 0\n        ? fields.map((fieldName) => sqlString.escapeId(fieldName)).join(', ')\n        : '*';\n    return `SELECT ${selectItem}`;\n  }\n\n  const selectItem = Object.entries(fields)\n    .map(\n      (key) => `${sqlString.escapeId(key[0])} AS ${sqlString.escapeId(key[1])}`,\n    )\n    .join(', ');\n  return `SELECT ${selectItem}`;\n}\n\n/**\n * Formats SQL JOIN clause from array of join configurations\n * @param joinObject Array of join options\n * @returns Formatted JOIN clause\n */\nexport function formatJoinClause(joinObject: JoinOptions[]) {\n  return joinObject\n    .map(\n      (data) =>\n        `${data.type ? data.type + ' JOIN' : 'INNER JOIN'} ${sqlString.escapeId(\n          data.table,\n        )} ON ${data.on}`,\n    )\n    .join(' ');\n}\n\n/**\n * Converts degrees to radians\n * @param angle Angle in degrees\n * @returns Angle in radians\n */\nfunction degree2radian(angle: number) {\n  return (angle * Math.PI) / 180;\n}\n\n/**\n * Converts radians to degrees\n * @param angle Angle in radians\n * @returns Angle in degrees\n */\nfunction radian2degree(angle: number) {\n  return (angle / Math.PI) * 180;\n}\n\nconst EARTH_RADIUS_METERS = 6371000;\n\n/**\n * Creates SQL WHERE clause for geographic bounding box search\n * @param latitudeDegree Center latitude in degrees\n * @param longitudeDegree Center longitude in degrees\n * @param boundingBoxSideMeters Size of bounding box in meters\n * @returns SQL WHERE clause for bounding box search\n */\nexport function formatWhereClauseBoundingBox(\n  latitudeDegree: number | string,\n  longitudeDegree: number | string,\n  boundingBoxSideMeters: number,\n): string {\n  const lat = Number(latitudeDegree);\n  const lon = Number(longitudeDegree);\n\n  if (\n    isNaN(lat) ||\n    isNaN(lon) ||\n    lat < -90 ||\n    lat > 90 ||\n    lon < -180 ||\n    lon > 180\n  ) {\n    throw new Error('Invalid latitude or longitude values');\n  }\n\n  const latitudeRadian = degree2radian(lat);\n  const radiusFromLatitude = Math.cos(latitudeRadian) * EARTH_RADIUS_METERS;\n\n  const halfSide = boundingBoxSideMeters / 2;\n  const deltaLatitude = radian2degree(halfSide / EARTH_RADIUS_METERS);\n  const deltaLongitude = radian2degree(halfSide / radiusFromLatitude);\n\n  return [\n    `stop_lat BETWEEN ${lat - deltaLatitude} AND ${lat + deltaLatitude}`,\n    `stop_lon BETWEEN ${lon - deltaLongitude} AND ${lon + deltaLongitude}`,\n  ].join(' AND ');\n}\n\n/**\n * Formats SQL WHERE clause for a single key-value pair\n * @param key Column name\n * @param value Single value, array of values, or null\n * @returns Formatted WHERE clause condition\n */\nexport function formatWhereClause(\n  key: string,\n  value: null | SqlValue | SqlValue[],\n) {\n  if (Array.isArray(value)) {\n    let whereClause = `${sqlString.escapeId(key)} IN (${value\n      .filter((v) => v !== null)\n      .map((v) => sqlString.escape(v))\n      .join(', ')})`;\n\n    if (value.includes(null)) {\n      whereClause = `(${whereClause} OR ${sqlString.escapeId(key)} IS NULL)`;\n    }\n\n    return whereClause;\n  }\n\n  if (value === null) {\n    return `${sqlString.escapeId(key)} IS NULL`;\n  }\n\n  return `${sqlString.escapeId(key)} = ${sqlString.escape(value)}`;\n}\n\n/**\n * Formats complete SQL WHERE clause from query object\n * @param query Object containing column-value pairs\n * @returns Formatted WHERE clause or empty string if no conditions\n */\nexport function formatWhereClauses(query: SqlWhere) {\n  if (Object.keys(query).length === 0) {\n    return '';\n  }\n\n  const whereClauses = Object.entries(query).map(([key, value]) =>\n    formatWhereClause(key, value),\n  );\n  return `WHERE ${whereClauses.join(' AND ')}`;\n}\n\n/**\n * Formats SQL ORDER BY clause from array of sorting criteria\n * @param orderBy Array of [column, direction] tuples\n * @returns Formatted ORDER BY clause\n */\nexport function formatOrderByClause(orderBy: SqlOrderBy) {\n  let orderByClause = '';\n\n  if (orderBy.length > 0) {\n    orderByClause += 'ORDER BY ';\n\n    orderByClause += orderBy\n      .map(([key, value]) => {\n        const direction = value === 'DESC' ? 'DESC' : 'ASC';\n        return `${sqlString.escapeId(key)} ${direction}`;\n      })\n      .join(', ');\n  }\n\n  return orderByClause;\n}\n\n/**\n * Gets day of week name from YYYYMMDD date number\n * @param date Date in YYYYMMDD format\n * @returns Lowercase day name (sunday-saturday)\n */\nexport function getDayOfWeekFromDate(date: number): string {\n  const DAYS_OF_WEEK = [\n    'sunday',\n    'monday',\n    'tuesday',\n    'wednesday',\n    'thursday',\n    'friday',\n    'saturday',\n  ] as const;\n\n  if (!Number.isInteger(date) || date.toString().length !== 8) {\n    throw new Error('Date must be in YYYYMMDD format');\n  }\n\n  const year = Math.floor(date / 10000);\n  const month = Math.floor((date % 10000) / 100);\n  const day = date % 100;\n\n  const dateObj = new Date(year, month - 1, day);\n\n  if (dateObj.toString() === 'Invalid Date') {\n    throw new Error('Invalid date');\n  }\n\n  return DAYS_OF_WEEK[dateObj.getDay()];\n}\n\n/**\n * Formats a numeric value according to the decimal precision rules of the specified currency,\n * without any currency symbols or separators.\n * @param value The numeric value to format (e.g., 10.5)\n * @param currency The ISO 4217 currency code (e.g., 'USD', 'JPY', 'EUR')\n * @returns The formatted string with appropriate decimal places\n *          Examples:\n *          - formatCurrency(10.5, 'USD') => '10.50'    // USD uses 2 decimal places\n *          - formatCurrency(10.5, 'JPY') => '10'       // JPY uses 0 decimal places\n *          - formatCurrency(10.523, 'BHD') => '10.523' // BHD uses 3 decimal places\n */\nexport function formatCurrency(value: number, currency: string) {\n  const parts = new Intl.NumberFormat(undefined, {\n    style: 'currency',\n    currency,\n  }).formatToParts(value);\n\n  const integerPart =\n    parts.find((part) => part.type === 'integer')?.value ?? '0';\n  const fractionPart =\n    parts.find((part) => part.type === 'fraction')?.value ?? '';\n\n  return `${integerPart}${fractionPart !== '' ? `.${fractionPart}` : ''}`;\n}\n\n/**\n * Gets the timestamp column name for a given column name\n * @param columnName The column name\n * @returns The timestamp column name\n */\nexport function getTimestampColumnName(columnName: string) {\n  return columnName.endsWith('time')\n    ? `${columnName}stamp`\n    : `${columnName}_timestamp`;\n}\n\n/**\n * Applies a prefix to a value if the column should be prefixed and the value is not null\n * @param value The value to prefix\n * @param columnShouldBePrefixed Whether the column should be prefixed\n * @param prefix The prefix to apply\n * @returns The value with the prefix applied if the column should be prefixed and the value is not null\n */\nexport function applyPrefixToValue(\n  value: string,\n  columnShouldBePrefixed?: boolean,\n  prefix?: string,\n) {\n  if (!columnShouldBePrefixed || prefix === undefined || value === null) {\n    return value;\n  }\n\n  return `${prefix}${value}`;\n}\n\n/**\n * Pluralizes a word based on the count\n * @param singularWord The singular word\n * @param pluralWord The plural word\n * @param count The count of the word\n * @returns The pluralized word\n */\nexport function pluralize(\n  singularWord: string,\n  pluralWord: string,\n  count: number,\n) {\n  return count === 1 ? singularWord : pluralWord;\n}\n","import path from 'node:path';\nimport { writeFile } from 'node:fs/promises';\n\nimport { without, compact } from 'lodash-es';\nimport { stringify } from 'csv-stringify';\nimport sqlString from 'sqlstring-sqlite';\nimport Database from 'better-sqlite3';\nimport mapSeries from 'promise-map-series';\n\nimport * as models from '../models/models.ts';\nimport { openDb } from './db.ts';\nimport { prepDirectory, generateFolderName, untildify } from './file-utils.ts';\nimport { log, logWarning } from './log-utils.ts';\nimport { formatCurrency, pluralize, setDefaultConfig } from './utils.ts';\n\nimport { Config, Model, SqlValue } from '../types/global_interfaces.ts';\n\nconst getAgencies = (db: Database.Database, config: Config) => {\n  try {\n    return db.prepare('SELECT agency_name FROM agency;').all() as {\n      agency_name: string;\n    }[];\n  } catch {\n    if (config.sqlitePath === ':memory:') {\n      throw new Error(\n        'No agencies found in SQLite. You are using an in-memory database - if running this from command line be sure to specify a value for `sqlitePath` in config.json other than \":memory:\".',\n      );\n    }\n\n    throw new Error(\n      'No agencies found in SQLite. Be sure to first import data into SQLite using `gtfs-import` or `importGtfs(config);`',\n    );\n  }\n};\n\nexport const exportGtfs = async (initialConfig: Config) => {\n  const config = setDefaultConfig(initialConfig);\n  const db = openDb(config);\n\n  // Get agency name for export folder from first line of agency.txt\n\n  const agencies = getAgencies(db, config);\n  const agencyCount = agencies.length;\n  if (agencyCount === 0) {\n    throw new Error(\n      'No agencies found in SQLite. Be sure to first import data into SQLite using `gtfs-import` or `importGtfs(config);`',\n    );\n  } else if (agencyCount > 1) {\n    logWarning(config)(\n      'More than one agency is defined in config.json. Export will merge all into one GTFS file.',\n    );\n  }\n\n  log(config)(\n    `Starting GTFS export for ${pluralize(\n      'agency',\n      'agencies',\n      agencyCount,\n    )} using SQLite database at ${config.sqlitePath}`,\n  );\n\n  const folderName = generateFolderName(agencies[0].agency_name);\n  const defaultExportPath = path.join(process.cwd(), 'gtfs-export', folderName);\n  const exportPath = untildify(config.exportPath || defaultExportPath);\n\n  await prepDirectory(exportPath);\n\n  // Loop through each GTFS file\n  const modelsToExport = (Object.values(models) as Model[]).filter(\n    (model) => model.extension !== 'gtfs-realtime',\n  );\n  const exportedFiles = await mapSeries(\n    modelsToExport,\n    async (model: Model) => {\n      const filePath = path.join(\n        exportPath,\n        `${model.filenameBase}.${model.filenameExtension}`,\n      );\n      const tableName = sqlString.escapeId(model.filenameBase);\n      const lines = db.prepare(`SELECT * FROM ${tableName};`).all() as Array<\n        Record<string, SqlValue>\n      >;\n\n      if (!lines || lines.length === 0) {\n        if (!model.nonstandard) {\n          log(config)(\n            `Skipping (no data) - ${model.filenameBase}.${model.filenameExtension}\\r`,\n          );\n        }\n\n        return;\n      }\n\n      if (model.filenameExtension === 'txt') {\n        const excludeColumns = [];\n\n        // If no routes have values for agency_id, add it to the excludeColumns list\n        if (model.filenameBase === 'routes') {\n          const routesWithAgencyId = db\n            .prepare(\n              'SELECT agency_id FROM routes WHERE agency_id IS NOT NULL;',\n            )\n            .all();\n          if (!routesWithAgencyId || routesWithAgencyId.length === 0) {\n            excludeColumns.push('agency_id');\n          }\n        } else if (model.filenameBase === 'fare_attributes') {\n          for (const line of lines) {\n            line.price = formatCurrency(\n              line.price as number,\n              line.currency_type as string,\n            );\n          }\n        } else if (model.filenameBase === 'fare_products') {\n          for (const line of lines) {\n            line.amount = formatCurrency(\n              line.amount as number,\n              line.currency as string,\n            );\n          }\n        }\n\n        const columns = without(\n          model.schema.map((column) => column.name),\n          ...excludeColumns,\n        );\n        const fileText = await stringify(lines, { columns, header: true });\n        await writeFile(filePath, fileText);\n      } else if (model.filenameExtension === 'geojson') {\n        const fileText = lines?.[0].geojson ?? '';\n        await writeFile(filePath, fileText as string);\n      } else {\n        throw new Error(\n          `Unexpected filename extension: ${model.filenameExtension}`,\n        );\n      }\n\n      log(config)(\n        `Exporting - ${model.filenameBase}.${model.filenameExtension}\\r`,\n      );\n\n      return `${model.filenameBase}.${model.filenameExtension}`;\n    },\n  );\n\n  if (compact(exportedFiles).length === 0) {\n    log(config)(\n      'No GTFS data exported. Be sure to first import data into SQLite.',\n    );\n    return;\n  }\n\n  log(config)(`Completed GTFS export to ${exportPath}`);\n\n  log(config)(\n    `Completed GTFS export for ${pluralize('agency', 'agencies', agencyCount)}\\n`,\n  );\n};\n","import sqlString from 'sqlstring-sqlite';\nimport Database from 'better-sqlite3';\n\nimport { openDb } from './db.ts';\n\nimport {\n  formatOrderByClause,\n  formatSelectClause,\n  formatWhereClauses,\n  formatJoinClause,\n} from './utils.ts';\n\nimport type {\n  JoinOptions,\n  QueryOptions,\n  SqlOrderBy,\n  SqlWhere,\n  SqlValue,\n} from '../types/global_interfaces.ts';\n\n/*\n * Returns an array of all agencies that match the query parameters.\n */\nexport function advancedQuery(\n  table: string,\n  advancedQueryOptions: {\n    db?: Database.Database;\n    query?: SqlWhere;\n    fields?: string[];\n    orderBy?: SqlOrderBy;\n    join?: JoinOptions[];\n    options?: QueryOptions;\n  },\n) {\n  const defaultOptions: {\n    query: SqlWhere;\n    fields: string[];\n    orderBy: SqlOrderBy;\n    join: JoinOptions[];\n    options: QueryOptions;\n  } = {\n    query: {},\n    fields: [],\n    orderBy: [],\n    join: [],\n    options: {},\n  };\n  const queryOptions = { ...defaultOptions, ...advancedQueryOptions };\n\n  const db = queryOptions.options.db ?? openDb();\n  const tableName = sqlString.escapeId(table);\n  const selectClause = formatSelectClause(queryOptions.fields);\n  const whereClause = formatWhereClauses(queryOptions.query);\n  const joinClause = formatJoinClause(queryOptions.join);\n  const orderByClause = formatOrderByClause(queryOptions.orderBy);\n  return db\n    .prepare(\n      `${selectClause} FROM ${tableName} ${joinClause} ${whereClause} ${orderByClause};`,\n    )\n    .all() as Array<Record<string, SqlValue>>;\n}\n","import { omit, pick } from 'lodash-es';\n\nimport type {\n  QueryOptions,\n  Route,\n  SqlOrderBy,\n  QueryResult,\n  SqlWhere,\n} from '../../types/global_interfaces.ts';\nimport { openDb } from '../db.ts';\nimport {\n  formatOrderByClause,\n  formatSelectClause,\n  formatWhereClause,\n  formatWhereClauses,\n} from '../utils.ts';\n\nfunction buildStoptimeSubquery(query: { [key: string]: string }) {\n  const whereClause = formatWhereClauses(query);\n  return `SELECT DISTINCT trip_id FROM stop_times ${whereClause}`;\n}\n\nfunction buildTripSubquery(query: { service_id?: string; stop_id?: string }) {\n  let whereClause = '';\n  const tripQuery = omit(query, ['stop_id']);\n  const stoptimeQuery = pick(query, ['stop_id']);\n\n  const whereClauses = Object.entries(tripQuery).map(([key, value]) =>\n    formatWhereClause(key, value),\n  );\n\n  if (Object.values(stoptimeQuery).length > 0) {\n    whereClauses.push(`trip_id IN (${buildStoptimeSubquery(stoptimeQuery)})`);\n  }\n\n  if (whereClauses.length > 0) {\n    whereClause = `WHERE ${whereClauses.join(' AND ')}`;\n  }\n\n  return `SELECT DISTINCT route_id FROM trips ${whereClause}`;\n}\n\n/*\n * Returns an array of routes that match the query parameters. A `stop_id`\n * query parameter may be passed to find all routes that contain that stop.\n * A `service_id` query parameter may be passed to limit routes to specific\n * calendars.\n */\nexport function getRoutes<Fields extends keyof Route>(\n  query: SqlWhere = {},\n  fields: Fields[] = [],\n  orderBy: SqlOrderBy = [],\n  options: QueryOptions = {},\n) {\n  const db = options.db ?? openDb();\n  const tableName = 'routes';\n  const selectClause = formatSelectClause(fields);\n  let whereClause = '';\n  const orderByClause = formatOrderByClause(orderBy);\n  const routeQuery = omit(query, ['stop_id', 'service_id']);\n  const tripQuery = pick(query, ['stop_id', 'service_id']) as {\n    stop_id?: string;\n    service_id?: string;\n  };\n\n  const whereClauses = Object.entries(routeQuery).map(([key, value]) =>\n    formatWhereClause(key, value),\n  );\n\n  if (Object.values(tripQuery).length > 0) {\n    whereClauses.push(`route_id IN (${buildTripSubquery(tripQuery)})`);\n  }\n\n  if (whereClauses.length > 0) {\n    whereClause = `WHERE ${whereClauses.join(' AND ')}`;\n  }\n\n  return db\n    .prepare(\n      `${selectClause} FROM ${tableName} ${whereClause} ${orderByClause};`,\n    )\n    .all() as QueryResult<Route, Fields>[];\n}\n","import { compact, omit, pick } from 'lodash-es';\nimport { FeatureCollection } from 'geojson';\nimport { featureCollection } from '@turf/helpers';\n\nimport type {\n  QueryOptions,\n  Shape,\n  SqlOrderBy,\n  QueryResult,\n  SqlWhere,\n} from '../../types/global_interfaces.ts';\nimport { openDb } from '../db.ts';\nimport {\n  formatOrderByClause,\n  formatSelectClause,\n  formatWhereClause,\n  formatWhereClauses,\n} from '../utils.ts';\nimport { shapesToGeoJSONFeature } from '../geojson-utils.ts';\nimport { getAgencies } from './agencies.ts';\nimport { getRoutes } from './routes.ts';\nimport { getRouteAttributes } from '../gtfs-plus/route-attributes.ts';\n\nfunction buildTripSubquery(query: { [key: string]: string | number }) {\n  const whereClause = formatWhereClauses(query);\n  return `SELECT DISTINCT shape_id FROM trips ${whereClause}`;\n}\n\n/*\n * Returns array of shapes that match the query parameters. A `route_id` query\n * parameter may be passed to find all shapes for a route. A `trip_id` query\n * parameter may be passed to find all shapes for a trip. A `direction_id`\n * query parameter may be passed to find all shapes for a direction.\n */\nexport function getShapes<Fields extends keyof Shape>(\n  query: SqlWhere = {},\n  fields: Fields[] = [],\n  orderBy: SqlOrderBy = [],\n  options: QueryOptions = {},\n) {\n  const db = options.db ?? openDb();\n  const tableName = 'shapes';\n  const selectClause = formatSelectClause(fields);\n  let whereClause = '';\n  const orderByClause = formatOrderByClause(orderBy);\n\n  const shapeQuery = omit(query, [\n    'route_id',\n    'trip_id',\n    'service_id',\n    'direction_id',\n  ]);\n  const tripQuery = pick(query, [\n    'route_id',\n    'trip_id',\n    'service_id',\n    'direction_id',\n  ]) as {\n    route_id?: string;\n    trip_id?: string;\n    service_id?: string;\n    direction_id?: number;\n  };\n\n  const whereClauses = Object.entries(shapeQuery).map(([key, value]) =>\n    formatWhereClause(key, value),\n  );\n\n  if (Object.values(tripQuery).length > 0) {\n    whereClauses.push(`shape_id IN (${buildTripSubquery(tripQuery)})`);\n  }\n\n  if (whereClauses.length > 0) {\n    whereClause = `WHERE ${whereClauses.join(' AND ')}`;\n  }\n\n  return db\n    .prepare(\n      `${selectClause} FROM ${tableName} ${whereClause} ${orderByClause};`,\n    )\n    .all() as QueryResult<Shape, Fields>[];\n}\n\n/*\n * Returns geoJSON of the shapes that match the query parameters. A `route_id`\n * query parameter may be passed to find all shapes for a route. A `trip_id`\n * query parameter may be passed to find all shapes for a trip. A\n * `direction_id` query parameter may be passed to find all shapes for a direction.\n */\nexport function getShapesAsGeoJSON(\n  query: SqlWhere = {},\n  options: QueryOptions = {},\n): FeatureCollection {\n  const agencies = getAgencies({}, [], [], options);\n  const routeQuery = pick(query, ['route_id']);\n  const routes = getRoutes(routeQuery, [], [], options);\n  const features = compact(\n    routes.map((route) => {\n      const shapeQuery = {\n        route_id: route.route_id,\n        ...omit(query, 'route_id'),\n      };\n      const shapes = getShapes(\n        shapeQuery,\n        ['shape_id', 'shape_pt_sequence', 'shape_pt_lon', 'shape_pt_lat'],\n        [],\n        options,\n      );\n\n      if (shapes.length === 0) {\n        return;\n      }\n\n      const routeAttributes = getRouteAttributes(\n        { route_id: route.route_id },\n        [],\n        [],\n        options,\n      );\n\n      const agency = agencies.find(\n        (agency) => agency.agency_id === route.agency_id,\n      );\n\n      const geojsonProperties = {\n        agency_name: agency ? agency.agency_name : undefined,\n        shape_id: query.shape_id,\n        ...route,\n        ...(routeAttributes?.[0] || []),\n      };\n      return shapesToGeoJSONFeature(shapes, geojsonProperties);\n    }),\n  );\n\n  return featureCollection(features);\n}\n","import { omit, orderBy, pick } from 'lodash-es';\nimport { FeatureCollection } from 'geojson';\n\nimport type {\n  QueryOptions,\n  SqlOrderBy,\n  QueryResult,\n  SqlWhere,\n  Stop,\n  SqlValue,\n} from '../../types/global_interfaces.ts';\nimport { openDb } from '../db.ts';\nimport {\n  formatOrderByClause,\n  formatSelectClause,\n  formatWhereClause,\n  formatWhereClauseBoundingBox,\n  formatWhereClauses,\n} from '../utils.ts';\nimport { stopsToGeoJSONFeatureCollection } from '../geojson-utils.ts';\nimport { getAgencies } from './agencies.ts';\nimport { getStopAttributes } from '../gtfs-plus/stop-attributes.ts';\n\nfunction buildTripSubquery(query: { [key: string]: SqlValue }) {\n  const whereClause = formatWhereClauses(query);\n  return `SELECT trip_id FROM trips ${whereClause}`;\n}\n\nfunction buildStoptimeSubquery(query: { [key: string]: SqlValue }) {\n  return `SELECT DISTINCT stop_id FROM stop_times WHERE trip_id IN (${buildTripSubquery(\n    query,\n  )})`;\n}\n\n/*\n * Returns an array of stops that match the query parameters. A `route_id`\n * query parameter may be passed to find all shapes for a route. A `trip_id`\n * query parameter may be passed to find all shapes for a trip. A\n * `direction_id` query parameter may be passed to find all shapes for a\n * direction.\n */\nexport function getStops<Fields extends keyof Stop>(\n  query: SqlWhere = {},\n  fields: Fields[] = [],\n  orderBy: SqlOrderBy = [],\n  options: QueryOptions = {},\n) {\n  const db = options.db ?? openDb();\n  const tableName = 'stops';\n  const selectClause = formatSelectClause(fields);\n  let whereClause = '';\n  let orderByClause = formatOrderByClause(orderBy);\n\n  const stopQueryOmitKeys = [\n    'route_id',\n    'trip_id',\n    'service_id',\n    'direction_id',\n    'shape_id',\n  ];\n\n  // If bounding_box_side_m is defined, search for stops inside a bounding box so omit `stop_lat` and `stop_lon`.\n  if (options.bounding_box_side_m !== undefined) {\n    stopQueryOmitKeys.push('stop_lat', 'stop_lon');\n  }\n\n  const stopQuery = omit(query, stopQueryOmitKeys);\n\n  const tripQuery = pick(query, [\n    'route_id',\n    'trip_id',\n    'service_id',\n    'direction_id',\n    'shape_id',\n  ]) as {\n    route_id?: string;\n    trip_id?: string;\n    service_id?: string;\n    direction_id?: number;\n    shape_id?: string;\n  };\n\n  const whereClauses = Object.entries(stopQuery).map(([key, value]) =>\n    formatWhereClause(key, value as SqlValue),\n  );\n\n  if (\n    options.bounding_box_side_m !== undefined &&\n    query.stop_lat !== undefined &&\n    query.stop_lon !== undefined\n  ) {\n    whereClauses.push(\n      formatWhereClauseBoundingBox(\n        query.stop_lat as number | string,\n        query.stop_lon as number | string,\n        options.bounding_box_side_m,\n      ),\n    );\n\n    // Add distance-based sorting if bounding_box_side_m is set and no other orderBy is set\n    if (orderBy.length === 0) {\n      orderByClause = `ORDER BY (((stop_lat - ${query.stop_lat}) * (stop_lat - ${query.stop_lat})) + ((stop_lon - ${query.stop_lon}) * (stop_lon - ${query.stop_lon}))) ASC`;\n    }\n  }\n\n  if (Object.values(tripQuery).length > 0) {\n    whereClauses.push(`stop_id IN (${buildStoptimeSubquery(tripQuery)})`);\n  }\n\n  if (whereClauses.length > 0) {\n    whereClause = `WHERE ${whereClauses.join(' AND ')}`;\n  }\n\n  return db\n    .prepare(\n      `${selectClause} FROM ${tableName} ${whereClause} ${orderByClause};`,\n    )\n    .all() as QueryResult<Stop, Fields>[];\n}\n\n/*\n * Returns geoJSON with stops.  A `route_id` query parameter may be passed to\n * find all shapes for a route. A `trip_id` query parameter may be passed to\n * find all shapes for a trip. A `direction_id` query parameter may be passed\n * to find all shapes for a direction.\n */\nexport function getStopsAsGeoJSON(\n  query: SqlWhere = {},\n  options: QueryOptions = {},\n): FeatureCollection {\n  const db = options.db ?? openDb();\n  const stops = getStops(query, [], [], options);\n\n  // Get all agencies for reference\n  const agencies = getAgencies({}, [], [], options);\n\n  const preparedStops = stops.map((stop) => {\n    const routeSubquery =\n      'SELECT DISTINCT route_id FROM trips WHERE trip_id IN (SELECT DISTINCT trip_id FROM stop_times WHERE stop_id = ?)';\n    const routes = db\n      .prepare(`SELECT * FROM routes WHERE route_id IN (${routeSubquery})`)\n      .all(stop.stop_id);\n\n    const stopAttributes = getStopAttributes({ stop_id: stop.stop_id });\n\n    return {\n      ...stop,\n      ...(stopAttributes?.[0] || []),\n      routes: orderBy(routes, (route: { route_short_name?: string }) =>\n        route?.route_short_name\n          ? Number.parseInt(route.route_short_name, 10)\n          : 0,\n      ),\n      agency_name: agencies[0].agency_name,\n    };\n  });\n\n  // Exclude stops not part of any route\n  const filteredStops = preparedStops.filter((stop) => stop.routes.length > 0);\n\n  return stopsToGeoJSONFeatureCollection(filteredStops);\n}\n","import { omit } from 'lodash-es';\nimport sqlString from 'sqlstring-sqlite';\nimport type {\n  QueryOptions,\n  SqlOrderBy,\n  QueryResult,\n  SqlWhere,\n  StopTime,\n  SqlValue,\n} from '../../types/global_interfaces.ts';\nimport { openDb } from '../db.ts';\nimport {\n  calculateSecondsFromMidnight,\n  formatOrderByClause,\n  formatSelectClause,\n  formatWhereClause,\n} from '../utils.ts';\nimport { getServiceIdsByDate } from './calendars.ts';\n\n/*\n * Returns an array of stoptimes that match the query parameters.\n */\nexport function getStoptimes<Fields extends keyof StopTime>(\n  query: SqlWhere = {},\n  fields: Fields[] = [],\n  orderBy: SqlOrderBy = [],\n  options: QueryOptions = {},\n) {\n  const db = options.db ?? openDb();\n  const tableName = 'stop_times';\n  const selectClause = formatSelectClause(fields);\n  let whereClause = '';\n  const orderByClause = formatOrderByClause(orderBy);\n\n  const stoptimeQueryOmitKeys = ['date', 'start_time', 'end_time'];\n\n  const stoptimeQuery = omit(query, stoptimeQueryOmitKeys);\n  const whereClauses = Object.entries(stoptimeQuery).map(([key, value]) =>\n    formatWhereClause(key, value as SqlValue),\n  );\n\n  if (query.date) {\n    if (typeof query.date !== 'number') {\n      throw new Error('`date` must be a number in yyyymmdd format');\n    }\n\n    const serviceIds = getServiceIdsByDate(query.date, options);\n\n    const tripSubquery = `SELECT DISTINCT trip_id FROM trips WHERE service_id IN (${serviceIds.map((id) => sqlString.escape(id)).join(',')})`;\n\n    whereClauses.push(`trip_id IN (${tripSubquery})`);\n  }\n\n  if (query.start_time) {\n    if (typeof query.start_time !== 'string') {\n      throw new Error('`start_time` must be a string in HH:mm:ss format');\n    }\n\n    whereClauses.push(\n      `arrival_timestamp >= ${calculateSecondsFromMidnight(query.start_time)}`,\n    );\n  }\n\n  if (query.end_time) {\n    if (typeof query.end_time !== 'string') {\n      throw new Error('`end_time` must be a string in HH:mm:ss format');\n    }\n\n    whereClauses.push(\n      `departure_timestamp <= ${calculateSecondsFromMidnight(query.end_time)}`,\n    );\n  }\n\n  if (whereClauses.length > 0) {\n    whereClause = `WHERE ${whereClauses.join(' AND ')}`;\n  }\n\n  return db\n    .prepare(\n      `${selectClause} FROM ${tableName} ${whereClause} ${orderByClause};`,\n    )\n    .all() as QueryResult<StopTime, Fields>[];\n}\n","import { omit } from 'lodash-es';\nimport sqlString from 'sqlstring-sqlite';\nimport type {\n  QueryOptions,\n  SqlOrderBy,\n  QueryResult,\n  SqlWhere,\n  Trip,\n  SqlValue,\n} from '../../types/global_interfaces.ts';\nimport { openDb } from '../db.ts';\nimport {\n  formatOrderByClause,\n  formatSelectClause,\n  formatWhereClause,\n} from '../utils.ts';\nimport { getServiceIdsByDate } from './calendars.ts';\n\n/*\n * Returns an array of all trips that match the query parameters.\n */\nexport function getTrips<Fields extends keyof Trip>(\n  query: SqlWhere = {},\n  fields: Fields[] = [],\n  orderBy: SqlOrderBy = [],\n  options: QueryOptions = {},\n) {\n  const db = options.db ?? openDb();\n  const tableName = 'trips';\n  const selectClause = formatSelectClause(fields);\n  let whereClause = '';\n  const orderByClause = formatOrderByClause(orderBy);\n\n  const tripQueryOmitKeys = ['date'];\n\n  const tripQuery = omit(query, tripQueryOmitKeys);\n\n  const whereClauses = Object.entries(tripQuery).map(([key, value]) =>\n    formatWhereClause(key, value as SqlValue),\n  );\n\n  if (query.date) {\n    if (typeof query.date !== 'number') {\n      throw new Error('`date` must be a number in yyyymmdd format');\n    }\n\n    const serviceIds = getServiceIdsByDate(query.date, options);\n\n    whereClauses.push(\n      `service_id IN (${serviceIds.map((id) => sqlString.escape(id)).join(',')})`,\n    );\n  }\n\n  if (whereClauses.length > 0) {\n    whereClause = `WHERE ${whereClauses.join(' AND ')}`;\n  }\n\n  return db\n    .prepare(\n      `${selectClause} FROM ${tableName} ${whereClause} ${orderByClause};`,\n    )\n    .all() as QueryResult<Trip, Fields>[];\n}\n"],"mappings":";;;AAEA,OAAO,WAAW;AAClB,SAAS,eAAe;AACxB,OAAO,iBAAiB;;;ACJxB,OAAO,UAAU;AACjB,SAAS,kBAAkB;AAC3B,SAAS,eAAe;AACxB,SAAS,OAAO,UAAU,UAAU;AACpC,SAAS,MAAM,iBAAiB;AAChC,OAAO,cAAc;AACrB,OAAO,eAAe;;;ACNtB,SAAS,WAAW,gBAAgB;AACpC,SAAS,YAAY;AACrB,YAAY,YAAY;AAejB,SAAS,IAAI,QAA6B;AAC/C,MAAI,OAAO,YAAY,OAAO;AAC5B,WAAO;AAAA,EACT;AAEA,MAAI,OAAO,aAAa;AACtB,WAAO,OAAO;AAAA,EAChB;AAEA,SAAO,CAAC,MAAc,YAAY,UAAgB;AAChD,QAAI,aAAa,QAAQ,OAAO,OAAO;AACrC,gBAAU,QAAQ,QAAQ,CAAC;AAC3B,eAAS,QAAQ,QAAQ,CAAC;AAAA,IAC5B,OAAO;AACL,cAAQ,OAAO,MAAM,IAAI;AAAA,IAC3B;AAEA,YAAQ,OAAO,MAAM,IAAI;AAAA,EAC3B;AACF;AAUO,SAAS,WAAW,QAAwC;AACjE,MAAI,OAAO,aAAa;AACtB,WAAO,OAAO;AAAA,EAChB;AAEA,SAAO,CAAC,SAAuB;AAC7B,YAAQ,OAAO,MAAM;AAAA,EAAK,cAAc,IAAI,CAAC;AAAA,CAAI;AAAA,EACnD;AACF;AAUO,SAAS,SAAS,QAAwC;AAC/D,MAAI,OAAO,aAAa;AACtB,WAAO,OAAO;AAAA,EAChB;AAEA,SAAO,CAAC,SAAuB;AAC7B,YAAQ,OAAO,MAAM;AAAA,EAAK,YAAY,IAAI,CAAC;AAAA,CAAI;AAAA,EACjD;AACF;AAUO,SAAS,cAAc,MAAsB;AAClD,SAAc,cAAO,GAAU,iBAAU,SAAS,CAAC,KAAK,IAAI,EAAE;AAChE;AAUO,SAAS,YAAY,OAA+B;AACzD,QAAM,cAAc,iBAAiB,QAAQ,MAAM,UAAU;AAC7D,QAAM,eAAe,YAAY,QAAQ,eAAe,EAAE;AAE1D,SAAc,WAAI,GAAU,iBAAU,OAAO,CAAC,KAAK,YAAY,EAAE;AACnE;;;ADxFA,IAAM,gBAAgB,QAAQ;AAmB9B,eAAsB,UAAUA,OAAmC;AACjE,MAAI;AACJ,MAAI;AAEJ,MAAI;AACF,QAAIA,MAAK,YAAY;AACnB,YAAM,aAAa,KAAK,QAAQ,UAAUA,MAAK,UAAU,CAAC;AAC1D,aAAO,MAAM,SAAS,YAAY,MAAM;AACxC,eAAS,OAAO,OAAO,KAAK,MAAM,IAAI,GAAGA,KAAI;AAAA,IAC/C,WAAWA,MAAK,YAAYA,MAAK,WAAWA,MAAK,YAAY;AAC3D,YAAM,WAAW;AAAA,QACf,GAAIA,MAAK,WAAW,CAAC,EAAE,MAAMA,MAAK,SAAS,CAAC,IAAI,CAAC;AAAA,QACjD,GAAIA,MAAK,UAAU,CAAC,EAAE,KAAKA,MAAK,QAAQ,CAAC,IAAI,CAAC;AAAA,MAChD;AAEA,eAAS;AAAA,QACP;AAAA,QACA,GAAG,KAAKA,OAAM,CAAC,QAAQ,KAAK,CAAC;AAAA,MAC/B;AAAA,IACF,WAAW,WAAW,KAAK,QAAQ,eAAe,CAAC,GAAG;AACpD,aAAO,MAAM,SAAS,KAAK,QAAQ,eAAe,GAAG,MAAM;AAC3D,eAAS,OAAO,OAAO,KAAK,MAAM,IAAI,GAAGA,KAAI;AAC7C,UAAI,MAAM,EAAE,wCAAwC;AAAA,IACtD,OAAO;AACL,YAAM,IAAI;AAAA,QACR;AAAA,MACF;AAAA,IACF;AAEA,WAAO;AAAA,EACT,SAAS,OAAO;AACd,QAAI,iBAAiB,aAAa;AAChC,YAAM,IAAI;AAAA,QACR,kFAAkF,MAAM,OAAO;AAAA,MACjG;AAAA,IACF;AACA,UAAM;AAAA,EACR;AACF;AA0DO,SAAS,UAAU,eAA+B;AACvD,SAAO,gBACH,cAAc,QAAQ,iBAAiB,aAAa,IACpD;AACN;;;AElIA,OAAOC,WAAU;AACjB,SAAS,kBAAkB,cAAAC,aAAY,iBAAiB;AACxD,SAAS,IAAI,SAAS,QAAQ,YAAAC,WAAU,MAAAC,KAAI,iBAAiB;AAC7D,SAAS,aAAa;AACtB,OAAO,oBAAoB;AAC3B,SAAS,0BAA0B;AACnC,OAAOC,gBAAe;;;ACNf,IAAM,cAAc;AAAA,EACzB,cAAc;AAAA,EACd,WAAW;AAAA,EACX,QAAQ;AAAA,IACN;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,SAAS;AAAA,MACT,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,EACF;AACF;;;AC9EO,IAAM,kBAAkB;AAAA,EAC7B,cAAc;AAAA,EACd,WAAW;AAAA,EACX,QAAQ;AAAA,IACN;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,EACF;AACF;;;ACvFO,IAAM,mBAAmB;AAAA,EAC9B,cAAc;AAAA,EACd,WAAW;AAAA,EACX,QAAQ;AAAA,IACN;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,SAAS;AAAA,MACT,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,KAAK;AAAA,MACL,KAAK;AAAA,MACL,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,KAAK;AAAA,MACL,KAAK;AAAA,MACL,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,KAAK;AAAA,MACL,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,EACF;AACF;;;ACzIO,IAAM,gBAAgB;AAAA,EAC3B,cAAc;AAAA,EACd,WAAW;AAAA,EACX,QAAQ;AAAA,IACN;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,SAAS;AAAA,MACT,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,EACF;AACF;;;ACxFO,IAAM,+BAA+B;AAAA,EAC1C,cAAc;AAAA,EACd,WAAW;AAAA,EACX,QAAQ;AAAA,IACN;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,MACV,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,MACT,QAAQ;AAAA,IACV;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,OAAO;AAAA,MACP,QAAQ;AAAA,MACR,SAAS;AAAA,IACX;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,IACA;AAAA,MACE,MAAM;AAAA,MACN,MAAM;AAAA,MACN,UAAU;AAAA,IACZ;AAAA,EACF;AACF;;;AC3DA,OAAO,cAAc;AAIrB,IAAM,MAA4C,CAAC;AAEnD,SAAS,QAAQ,YAAoB;AACnC,QAAM,KAAK,IAAI,SAAS,UAAU,UAAU,CAAC;AAC7C,KAAG,OAAO,oBAAoB;AAC9B,KAAG,OAAO,mBAAmB;AAC7B,KAAG,OAAO,qBAAqB;AAC/B,MAAI,UAAU,IAAI;AAElB,SAAO;AACT;AAEO,SAAS,OACd,SAAiE,MAC9C;AAEnB,MAAI,QAAQ;AACV,UAAM,EAAE,aAAa,YAAY,GAAG,IAAI;AAGxC,QAAI,IAAI;AACN,aAAO;AAAA,IACT;AAGA,QAAI,IAAI,UAAU,GAAG;AACnB,aAAO,IAAI,UAAU;AAAA,IACvB;AAGA,WAAO,QAAQ,UAAU;AAAA,EAC3B;AAGA,MAAI,OAAO,KAAK,GAAG,EAAE,WAAW,GAAG;AACjC,WAAO,QAAQ,UAAU;AAAA,EAC3B;AAGA,MAAI,OAAO,KAAK,GAAG,EAAE,WAAW,GAAG;AACjC,UAAM,WAAW,OAAO,KAAK,GAAG,EAAE,CAAC;AACnC,WAAO,IAAI,QAAQ;AAAA,EACrB;AAEA,MAAI,OAAO,KAAK,GAAG,EAAE,SAAS,GAAG;AAC/B,UAAM,IAAI;AAAA,MACR;AAAA,IACF;AAAA,EACF;AAEA,QAAM,IAAI,MAAM,qCAAqC;AACvD;;;ACzDA;AAAA,EACE;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA,QAAAC;AAAA,EACA;AAAA,EACA;AAAA,OACK;AACP,SAAS,SAAS,yBAAyB;;;ACV3C,OAAO,0BAA0B;AACjC,OAAO,eAAe;AACtB,SAAS,WAAW;;;ACFpB,OAAO,eAAe;AACtB,OAAO,UAAU;AAeV,SAAS,wBAAwB,QAAgB;AACtD,MAAI,CAAC,OAAO,YAAY,OAAO,SAAS,WAAW,GAAG;AACpD,UAAM,IAAI,MAAM,mCAAmC;AAAA,EACrD;AAEA,aAAW,CAAC,OAAOC,OAAM,KAAK,OAAO,SAAS,QAAQ,GAAG;AACvD,QAAI,CAACA,QAAO,QAAQ,CAACA,QAAO,KAAK;AAC/B,YAAM,IAAI;AAAA,QACR,sEAAsE,KAAK;AAAA,MAC7E;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAOO,SAAS,iBAAiB,eAAuB;AACtD,QAAM,WAAW;AAAA,IACf,YAAY;AAAA,IACZ,kBAAkB;AAAA,IAClB,cAAc;AAAA,IACd,+BAA+B;AAAA,IAC/B,SAAS;AAAA,IACT,iBAAiB;AAAA,EACnB;AAEA,SAAO;AAAA,IACL,GAAG;AAAA,IACH,GAAG;AAAA,EACL;AACF;AAOO,SAAS,sBAAsB,UAInC;AACD,QAAM,EAAE,MAAM,KAAK,SAAS,IAAI;AAChC,SAAO,IAAI;AAAA,IACT,KAAK,SAAS,KAAK,MAAM,QAAQ,EAAE,SAAS,IAAI;AAAA,EAClD,EAAE,YAAY;AAChB;AAoRO,SAAS,mBACd,OACA,wBACA,QACA;AACA,MAAI,CAAC,0BAA0B,WAAW,UAAa,UAAU,MAAM;AACrE,WAAO;AAAA,EACT;AAEA,SAAO,GAAG,MAAM,GAAG,KAAK;AAC1B;AASO,SAAS,UACd,cACA,YACA,OACA;AACA,SAAO,UAAU,IAAI,eAAe;AACtC;;;ADjTA,IAAM,aAAa;AACnB,IAAM,cAAc;AACpB,IAAM,cAAc;AAKpB,SAAS,0BACP,QACA,QACA,MACA;AACA,MAAI,OAAO,SAAS,qBAAqB;AACvC,WAAO,KAAK;AAAA,EACd;AAEA,MAAI,OAAO,SAAS,wBAAwB;AAC1C,WAAO,KAAK,mBAAmB,KAAK;AAAA,EACtC;AAEA,QAAM,YACJ,OAAO,WAAW,SACd,OAAO,UACP,IAAI,QAAQ,OAAO,QAAQ,OAAO,OAAO;AAE/C,QAAM,oBAAoB,WAAW,aACjC,sBAAsB,SAAS,IAC/B;AAEJ,QAAM,gBAAgB;AAAA,IACpB;AAAA,IACA,OAAO;AAAA,IACP,KAAK;AAAA,EACP;AAEA,SAAO,OAAO,SAAS,SAAS,KAAK,UAAU,aAAa,IAAI;AAClE;AAKA,SAAS,wBAAwB,IAAuB,OAAc;AACpE,QAAM,UAAU,MAAM,OAAO,IAAI,CAAC,WAAwB,OAAO,IAAI;AACrE,QAAM,eAAe,MAAM,OAAO,IAAI,MAAM,GAAG,EAAE,KAAK,IAAI;AAE1D,SAAO,GAAG;AAAA,IACR,gBAAgB,MAAM,YAAY,KAAK,QAAQ,KAAK,IAAI,CAAC,aAAa,YAAY;AAAA,EACpF;AACF;AAKA,eAAe,aACb,OACA,WACA,WAC2B;AAC3B,MAAI,mBAAmB;AACvB,MAAI,kBAAkB;AAEtB,WAAS,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,WAAW;AAChD,UAAM,QAAQ,MAAM,MAAM,GAAG,IAAI,SAAS;AAC1C,QAAI;AACF,YAAM,SAAS,MAAM,UAAU,KAAK;AACpC,0BAAoB,OAAO;AAC3B,yBAAmB,OAAO;AAAA,IAC5B,SAAS,OAAgB;AACvB,YAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACvD,yBAAmB,MAAM;AACzB,cAAQ,MAAM,2BAA2B,YAAY,EAAE;AAAA,IACzD;AAAA,EACF;AAEA,SAAO,EAAE,aAAa,kBAAkB,YAAY,gBAAgB;AACtE;AAKA,eAAe,sBACb,MACA,MAC8B;AAC9B,QAAM,YAAY,aAAa,MAAM,IAAI;AAEzC,MAAI,CAAC,WAAW;AACd,WAAO;AAAA,EACT;AAEA,OAAK,IAAI,kCAAkC,UAAU,GAAG,EAAE;AAE1D,WAAS,UAAU,GAAG,WAAW,aAAa,WAAW;AACvD,QAAI;AACF,YAAM,WAAW,MAAM,MAAM,UAAU,KAAK;AAAA,QAC1C,QAAQ;AAAA,QACR,SAAS;AAAA,UACP,GAAI,UAAU,WAAW,CAAC;AAAA,UAC1B,mBAAmB;AAAA,QACrB;AAAA,QACA,QAAQ,KAAK,kBACT,YAAY,QAAQ,KAAK,eAAe,IACxC;AAAA,MACN,CAAC;AAED,UAAI,SAAS,WAAW,KAAK;AAC3B,cAAM,IAAI,MAAM,QAAQ,SAAS,MAAM,KAAK,SAAS,UAAU,EAAE;AAAA,MACnE;AAEA,YAAM,SAAS,MAAM,SAAS,YAAY;AAC1C,YAAM,UAAU,qBAAqB,iBAAiB,YAAY;AAAA,QAChE,IAAI,WAAW,MAAM;AAAA,MACvB;AAEA,YAAM,cACJ,qBAAqB,iBAAiB,YAAY,SAAS,SAAS;AAAA,QAClE,OAAO;AAAA,QACP,OAAO;AAAA,QACP,OAAO;AAAA,QACP,UAAU;AAAA,QACV,QAAQ;AAAA,QACR,SAAS;AAAA,QACT,QAAQ;AAAA,MACV,CAAC;AAEH,aAAO;AAAA,IACT,SAAS,OAAgB;AACvB,YAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACvD,UAAI,YAAY,aAAa;AAC3B,YAAI,KAAK,cAAc;AACrB,eAAK;AAAA,YACH,mBAAmB,IAAI,UAAU,WAAW,cAAc,YAAY;AAAA,UACxE;AACA,iBAAO;AAAA,QACT;AACA,cAAM;AAAA,MACR;AAEA,WAAK,WAAW,WAAW,OAAO,eAAe,IAAI,KAAK,YAAY,EAAE;AACxE,YAAM,IAAI;AAAA,QAAQ,CAAC,YACjB,WAAW,SAAS,cAAc,OAAO;AAAA,MAC3C;AAAA,IACF;AAAA,EACF;AAEA,SAAO;AACT;AAKA,SAAS,aACP,MACA,MAC+B;AAC/B,UAAQ,MAAM;AAAA,IACZ,KAAK;AACH,aAAO,KAAK;AAAA,IACd,KAAK;AACH,aAAO,KAAK;AAAA,IACd,KAAK;AACH,aAAO,KAAK;AAAA,IACd;AACE,aAAO;AAAA,EACX;AACF;AAKA,SAAS,6BACP,IACA,MACiC;AACjC,QAAM,YAAY,wBAAwB,IAAW,aAAsB;AAC3E,QAAM,qBAAqB;AAAA,IACzB;AAAA,IACO;AAAA,EACT;AAEA,SAAO,OAAO,UAAwD;AACpE,QAAI,cAAc;AAClB,QAAI,aAAa;AAEjB,OAAG,YAAY,MAAM;AACnB,iBAAW,UAAU,OAAO;AAC1B,YAAI;AAEF,gBAAM,cACG,cAAc,OACrB,IAAI,CAAC,WAAW,0BAA0B,QAAQ,QAAQ,IAAI,CAAC;AACjE,oBAAU,IAAI,WAAW;AACzB;AAGA,cAAI,OAAO,OAAO,gBAAgB,QAAQ;AACxC,uBAAW,kBAAkB,OAAO,MAAM,gBAAgB;AACxD,6BAAe,SAAS;AACxB,oBAAM,eACG,6BAA6B,OACpC;AAAA,gBAAI,CAAC,WACL,0BAA0B,gBAAgB,QAAQ,IAAI;AAAA,cACxD;AACA,iCAAmB,IAAI,YAAY;AACnC;AAAA,YACF;AAAA,UACF;AAAA,QACF,SAAS,OAAgB;AACvB,gBAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACvD;AACA,eAAK,WAAW,2BAA2B,YAAY,EAAE;AAAA,QAC3D;AAAA,MACF;AAAA,IACF,CAAC,EAAE;AAEH,WAAO,EAAE,aAAa,WAAW;AAAA,EACnC;AACF;AAKA,SAAS,2BACP,IACA,MACiC;AACjC,QAAM,iBAAiB;AAAA,IACrB;AAAA,IACO;AAAA,EACT;AACA,QAAM,eAAe;AAAA,IACnB;AAAA,IACO;AAAA,EACT;AAEA,SAAO,OAAO,UAAwD;AACpE,QAAI,cAAc;AAClB,QAAI,aAAa;AAEjB,OAAG,YAAY,MAAM;AACnB,iBAAW,UAAU,OAAO;AAC1B,YAAI;AAEF,gBAAM,mBACG,YAAY,OACnB,IAAI,CAAC,WAAW,0BAA0B,QAAQ,QAAQ,IAAI,CAAC;AACjE,yBAAe,IAAI,gBAAgB;AACnC;AAGA,cAAI,OAAO,YAAY,gBAAgB,QAAQ;AAC7C,uBAAW,kBAAkB,OAAO,WAAW,gBAAgB;AAC7D,6BAAe,SAAS;AACxB,oBAAM,iBACG,gBAAgB,OACvB;AAAA,gBAAI,CAAC,WACL,0BAA0B,gBAAgB,QAAQ,IAAI;AAAA,cACxD;AACA,2BAAa,IAAI,cAAc;AAC/B;AAAA,YACF;AAAA,UACF;AAAA,QACF,SAAS,OAAgB;AACvB,gBAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACvD;AACA,eAAK,WAAW,iCAAiC,YAAY,EAAE;AAAA,QACjE;AAAA,MACF;AAAA,IACF,CAAC,EAAE;AAEH,WAAO,EAAE,aAAa,WAAW;AAAA,EACnC;AACF;AAKA,SAAS,gCACP,IACA,MACiC;AACjC,QAAM,sBAAsB;AAAA,IAC1B;AAAA,IACO;AAAA,EACT;AAEA,SAAO,OAAO,UAAwD;AACpE,QAAI,cAAc;AAClB,QAAI,aAAa;AAEjB,OAAG,YAAY,MAAM;AACnB,iBAAW,UAAU,OAAO;AAC1B,YAAI;AACF,gBAAM,cACG,iBAAiB,OACxB,IAAI,CAAC,WAAW,0BAA0B,QAAQ,QAAQ,IAAI,CAAC;AACjE,8BAAoB,IAAI,WAAW;AACnC;AAAA,QACF,SAAS,OAAgB;AACvB,gBAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACvD;AACA,eAAK,WAAW,sCAAsC,YAAY,EAAE;AAAA,QACtE;AAAA,MACF;AAAA,IACF,CAAC,EAAE;AAEH,WAAO,EAAE,aAAa,WAAW;AAAA,EACnC;AACF;AAKA,SAAS,0BAA0B,QAAsB;AACvD,QAAM,KAAK,OAAO,MAAM;AAExB,MAAI,MAAM,EAAE,qCAAqC;AAEjD,KAAG,YAAY,MAAM;AACnB,UAAM,SAAS;AAAA,MACb;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,IACF;AAEA,eAAW,SAAS,QAAQ;AAC1B,SAAG;AAAA,QACD,eAAe,KAAK;AAAA,MACtB,EAAE,IAAI;AAAA,IACR;AAAA,EACF,CAAC,EAAE;AAEH,MAAI,MAAM,EAAE,wCAAwC,IAAI;AAC1D;AAKA,eAAsB,uBACpB,MACe;AACf,MACE,CAAC,KAAK,kBACN,CAAC,KAAK,uBACN,CAAC,KAAK,0BACN;AACA;AAAA,EACF;AAGA,QAAM,CAAC,YAAY,iBAAiB,oBAAoB,IAAI,MAAM,QAAQ;AAAA,IACxE;AAAA,MACE,KAAK,gBAAgB,MAAM,sBAAsB,UAAU,IAAI,IAAI;AAAA,MACnE,KAAK,qBAAqB,MACtB,sBAAsB,eAAe,IAAI,IACzC;AAAA,MACJ,KAAK,0BAA0B,MAC3B,sBAAsB,oBAAoB,IAAI,IAC9C;AAAA,IACN;AAAA,EACF;AAEA,QAAM,KAAK,OAAO,EAAE,YAAY,KAAK,WAAW,CAAC;AAEjD,QAAM,eAAe;AAAA,IACnB,QAAQ;AAAA,IACR,aAAa;AAAA,IACb,kBAAkB;AAAA,EACpB;AAGA,QAAM,qBAAsC,CAAC;AAE7C,MAAI,YAAY,QAAQ,QAAQ;AAC9B,uBAAmB;AAAA,MACjB;AAAA,QACE,WAAW;AAAA,QACX;AAAA,QACA,6BAA6B,IAAI,IAAI;AAAA,MACvC,EAAE,KAAK,CAAC,WAAW;AACjB,qBAAa,SAAS,OAAO;AAAA,MAC/B,CAAC;AAAA,IACH;AAAA,EACF;AAEA,MAAI,iBAAiB,QAAQ,QAAQ;AACnC,uBAAmB;AAAA,MACjB;AAAA,QACE,gBAAgB;AAAA,QAChB;AAAA,QACA,2BAA2B,IAAI,IAAI;AAAA,MACrC,EAAE,KAAK,CAAC,WAAW;AACjB,qBAAa,cAAc,OAAO;AAAA,MACpC,CAAC;AAAA,IACH;AAAA,EACF;AAEA,MAAI,sBAAsB,QAAQ,QAAQ;AACxC,uBAAmB;AAAA,MACjB;AAAA,QACE,qBAAqB;AAAA,QACrB;AAAA,QACA,gCAAgC,IAAI,IAAI;AAAA,MAC1C,EAAE,KAAK,CAAC,WAAW;AACjB,qBAAa,mBAAmB,OAAO;AAAA,MACzC,CAAC;AAAA,IACH;AAAA,EACF;AAGA,QAAM,QAAQ,IAAI,kBAAkB;AAEpC,OAAK;AAAA,IACH,kCAAkC,aAAa,MAAM,YAAY,aAAa,WAAW,kBAAkB,aAAa,gBAAgB;AAAA,EAC1I;AACF;AAKA,eAAsB,mBAAmB,eAAsC;AAC7E,QAAM,SAAS,iBAAiB,aAAa;AAC7C,0BAAwB,MAAM;AAE9B,MAAI;AACF,WAAO,MAAM;AAEb,UAAM,cAAc,OAAO,SAAS;AACpC,QAAI,MAAM;AAAA,MACR,sCAAsC;AAAA,QACpC;AAAA,QACA;AAAA,QACA;AAAA,MACF,CAAC,6BAA6B,OAAO,UAAU;AAAA,IACjD;AAEA,8BAA0B,MAAM;AAEhC,UAAM,UAAU,OAAO,UAAU,OAAOC,YAAyB;AAC/D,UAAI;AACF,cAAM,OAAyB;AAAA,UAC7B,gBAAgBA,QAAO;AAAA,UACvB,qBAAqBA,QAAO;AAAA,UAC5B,0BAA0BA,QAAO;AAAA,UACjC,iBAAiB,OAAO;AAAA,UACxB,+BAA+B,OAAO;AAAA,UACtC,cAAc,OAAO;AAAA,UACrB,YAAY,OAAO;AAAA,UACnB,QAAQA,QAAO;AAAA,UACf,kBAAkB,KAAK,MAAM,KAAK,IAAI,IAAI,GAAI;AAAA,UAC9C,KAAK,IAAI,MAAM;AAAA,UACf,YAAY,WAAW,MAAM;AAAA,UAC7B,UAAU,SAAS,MAAM;AAAA,QAC3B;AAEA,cAAM,uBAAuB,IAAI;AAAA,MACnC,SAAS,OAAgB;AACvB,cAAM,eACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AACvD,YAAI,OAAO,cAAc;AACvB,mBAAS,MAAM,EAAE,YAAY;AAAA,QAC/B,OAAO;AACL,gBAAM;AAAA,QACR;AAAA,MACF;AAAA,IACF,CAAC;AAED,QAAI,MAAM;AAAA,MACR,uCAAuC;AAAA,QACrC;AAAA,QACA;AAAA,QACA;AAAA,MACF,CAAC;AAAA;AAAA,IACH;AAAA,EACF,SAAS,OAAgB;AACvB,QAAK,MAAoC,SAAS,mBAAmB;AACnE,eAAS,MAAM;AAAA,QACb,mCAAmC,OAAO,UAAU;AAAA,MACtD;AAAA,IACF;AACA,UAAM;AAAA,EACR;AACF;;;AExiBA,OAAOC,WAAU;AACjB,SAAS,aAAAC,kBAAiB;AAE1B,SAAS,SAAS,WAAAC,gBAAe;AACjC,SAAS,iBAAiB;AAC1B,OAAOC,gBAAe;AAEtB,OAAOC,gBAAe;;;ACPtB,OAAOC,gBAAe;;;ACAtB,SAAS,QAAAC,OAAM,YAAY;;;ACA3B,SAAS,WAAAC,UAAS,QAAAC,OAAM,QAAAC,aAAY;AAEpC,SAAS,qBAAAC,0BAAyB;;;ACFlC,SAAS,QAAAC,OAAM,SAAS,QAAAC,aAAY;;;ACApC,SAAS,QAAAC,aAAY;AACrB,OAAOC,gBAAe;;;ACDtB,SAAS,QAAAC,aAAY;AACrB,OAAOC,gBAAe;;;AnBStB,IAAM,KAAK,IAAI,YAAY;AAE3B,IAAM,OAAO,MAAM,QAAQ,QAAQ,IAAI,CAAC,EACrC,MAAM,sCAAsC,EAC5C,KAAK,EACL,OAAO,KAAK;AAAA,EACX,OAAO;AAAA,EACP,UAAU;AAAA,EACV,MAAM;AACR,CAAC,EACA,QAAQ,cAAc,MAAS,EAC/B,UAAU;AAEb,IAAM,cAAc,CAAC,QAAQ,oBAAoB;AAC/C,UAAQ,OAAO,MAAM;AAAA,EAAK,YAAY,KAAK,CAAC;AAAA,CAAI;AAChD,UAAQ,MAAM,GAAG,OAAO,KAAK,CAAC;AAC9B,UAAQ,KAAK,CAAC;AAChB;AAEA,IAAM,cAAc,YAAY;AAC9B,QAAM,SAAS,MAAM,UAAU;AAAA,IAC7B,YAAY,KAAK;AAAA,EACnB,CAAC;AACD,QAAM,mBAAmB,MAAgB;AACzC,UAAQ,KAAK;AACf;AAEA,YAAY,EAAE,MAAM,WAAW;","names":["argv","path","existsSync","readFile","rm","mapSeries","omit","agency","agency","path","writeFile","compact","sqlString","mapSeries","sqlString","omit","compact","omit","pick","featureCollection","omit","pick","omit","sqlString","omit","sqlString"]}